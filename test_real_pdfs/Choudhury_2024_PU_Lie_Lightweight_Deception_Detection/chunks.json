{
  "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
  "metadata": {
    "title": "PU-Lie: Lightweight Deception Detection in Imbalanced Diplomatic Dialogues via Positive-Unlabeled Learning",
    "author": "Bhavinkumar Vinodbhai Kuwar; Bikrant Bikram Pratap Maurya; Priyanshu Gupta; Nitin Choudhury",
    "pages": 5,
    "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
    "pdf_library": "pypdf"
  },
  "num_chunks": 22,
  "chunks": [
    {
      "text": "a highly skewed class distribution that hinders conventional\nsupervised models. Traditional solutions like oversampling,\nundersampling, or cost-sensitive learning (e.g., class weights\nor focal loss [ 6]) have been employed, but these methods often\nintroduce overfitting or rely on noisy/missing negative labels. To overcome these limitations, an alternative\nparadigm\u2014Positive-Unlabeled (PU) Learning\u2014has been\nexplored in domains where only positive labels are reliable\nand negatives are ambiguous. PU learning has shown success\nin bioinformatics, fraud detection, and recommendation\nsystems [ 7], [ 8], as it estimates the risk of misclassification\nbased solely on the positive class and unlabeled examples.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c0",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 2,
      "chunk_index": 0,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 6672,
      "char_end": 7379,
      "prev_chunk_id": null,
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c1",
      "semantic_coherence": 0.0,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "Despite its relevance, PU learning has seen limited application\nin NLP, and to our knowledge, no prior work has applied it to\ndeception in strategic communication. Our work emphasizes\nthe importance of prioritizing rare deception cases over more\nabundant truthful ones. In parallel, models that combine deep learning with struc-\ntured and interpretable features are gaining traction. Stud-\nies like [ 9] highlight how integrating human-understandable\nfeatures (e.g., sentiment, discourse, power dynamics) with\nneural architectures can boost both accuracy and transparency.\n\nIn strategic games like Diplomacy, features such as power\nimbalance, pronoun usage, and game phase offer vital domain-\nspecific context often overlooked by purely neural models. Graph neural networks (GNNs) and dialogue-aware LSTMs\nhave also been explored to model player interactions [ 10], [11],\nbut these often suffer from overfitting under extreme class\nimbalance. Detecting deception is more critical than detecting truthful\ncommunication in this setting, as the consequences of missing\narXiv:2507.09157v1  [cs.CL]  12 Jul 2025\n\na lie can significantly affect strategic decisions. Hence, we\nprioritize models that perform well on the deceptive class.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c1",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 2,
      "chunk_index": 1,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 7380,
      "char_end": 8609,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c0",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c2",
      "semantic_coherence": 0.314339816570282,
      "has_citations": true,
      "topic_cluster": 0
    },
    {
      "text": "Traditional models often collapse to the majority class, failing\nto generalize or identify rare but impactful deceptive instances. To this end, we introduce PU-Lie, a novel application\nand a compact model for deception detection. It integrates\nfrozen BERT embeddings with handcrafted linguistic and\ngame-specific features and employs a Positive-Unlabeled (PU)\nlearning approach to handle data scarcity and imbalance. PU-\nLie not only achieves a new state-of-the-art macro F1-score\nof 0.60 but does so with only 1,345 trainable parameters\u2014a\n650\u00d7 reduction from prior models.\n\nTo this end, we introduce\nPU-Lie, a novel application and a compact model for decep-\ntion detection. It integrates frozen BERT embeddings with\nhandcrafted linguistic and game-specific features and employs\na Positive-Unlabeled (PU) learning approach to handle data\nscarcity and imbalance. PU-Lie not only achieves a new state-\nof-the-art macro F1-score of 0.60 but does so with only 1,345\ntrainable parameters\u2014a 650\u00d7 reduction from prior models. Research Gap. Existing work on deception detection in\nstrategic dialogues largely relies on fully supervised learning,\nassuming access to balanced datasets with clear negative labels.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c2",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 2,
      "chunk_index": 2,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 8609,
      "char_end": 9812,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c1",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c3",
      "semantic_coherence": 0.6616861820220947,
      "has_citations": false,
      "topic_cluster": 0
    },
    {
      "text": "However, this assumption breaks down in real-world scenarios\nlike Diplomacy, where deceptive messages are rare, unlabeled\nmessages dominate, and truth labels are often ambiguous or\nmissing. Moreover, most prior studies overlook the critical\nasymmetry in importance\u2014accurately detecting deception is far\nmore impactful than identifying truth. Despite this, few models\nhave explicitly prioritized deception or explored anomaly-based\napproaches such as Positive-Unlabeled (PU) learning to address\nthis skew. Finally, many existing models are computationally\ncomplex, limiting their applicability in low-resource or real-\ntime environments. This highlights the need for a lightweight,\ninterpretable, and deception-focused model that leverages PU\nlearning for effective detection in highly imbalanced dialogue\nsettings.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c3",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 2,
      "chunk_index": 3,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 9812,
      "char_end": 10626,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c2",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c4",
      "semantic_coherence": 0.7148851752281189,
      "has_citations": false,
      "topic_cluster": 0
    },
    {
      "text": "Research Questions: This study is motivated by the\nfollowing core research questions:\n1) Can anomaly detection-inspired techniques such as\nPositive-Unlabeled (PU) learning effectively address\nextreme class imbalance in deception detection tasks? 2) Does reducing the number of trainable parameters\nby several orders of magnitude (e.g., 650 \u00d7 fewer)\ncompromise the model\u2019s ability to detect subtle\ndeception cues? 3) Is a lightweight model, with minimal architecture and\nhandcrafted features, sufficient to capture deceptive\nintent in complex strategic dialogues? 4) To what extent do linguistic features\u2014such as hedg-\ning, pronoun usage, and sentiment\u2014contribute to\nidentifying lies in human language?\n\nOur main contributions are:\n\u2022 A PU-learning-based architecture that prioritizes deceptive\nmessage detection in highly imbalanced settings. \u2022 An interpretable and efficient feature set combining\nlinguistic signals and game-specific metadata. \u2022 Thorough experimentation across seven model variants,\ncovering deep, classical, and graph-based paradigms. \u2022 Focusing on deceptive messages rather than truthful. \u2022 A lightweight model with significantly less trainable\nparameters, a significant reduced training time and a\nsignificant reduced inference time. Our main contributions are:\n\u2022 A PU-learning-based architecture that prioritizes deceptive\nmessage detection in highly imbalanced settings.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c4",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 2,
      "chunk_index": 4,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 10627,
      "char_end": 12019,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c3",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p2_c5",
      "semantic_coherence": 0.8168249726295471,
      "has_citations": false,
      "topic_cluster": 0
    },
    {
      "text": "\u2022 An interpretable and efficient feature set combining\nlinguistic signals and game-specific metadata. \u2022 Thorough experimentation across seven model variants,\ncovering deep, classical, and graph-based paradigms. \u2022 Focusing on deceptive messages rather than truthful. \u2022 A lightweight model with significantly less trainable\nparameters, a significant reduced training time and a\nsignificant reduced inference time. II. R ELATED WORK\nDeception Detection.Early studies explored linguistic mark-\ners such as hedging, sentiment, and syntactic complexity\nto detect deception [ 1], [ 2], [ 12].\n\nWith the rise of deep\nlearning, models like RNNs and transformers have been\napplied to deception tasks on domains like fake reviews\nand misinformation [ 4], [5]. However, these assume balanced\ndatasets and often fail under severe class skew. Strategic Dialogue and Diplomacy. Peskov et al. (2020)\nintroduced the Diplomacy dataset\u2014a rare collection of real\ndeception instances from strategic gameplay. Their BERT +\nLSTM model set a benchmark but remained resource-heavy\nand under-optimized for imbalance. Imbalanced Learning.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p3_c5",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 3,
      "chunk_index": 5,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 12019,
      "char_end": 13130,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p3_c4",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p3_c6",
      "semantic_coherence": 0.8382631540298462,
      "has_citations": true,
      "topic_cluster": 0
    },
    {
      "text": "Traditional methods include class\nweighting, resampling, SMOTE [ 13] and focal loss [ 6], but\nthey still rely on supervised labels for both classes. These\nassumptions do not hold in deception tasks, where negative\nlabels may be ambiguous or missing. Positive-Unlabeled Learning. PU learning addresses sce-\nnarios with few labeled positives and many unlabeled samples. It estimates true risk using the known positive subset and class\nprior [7].\n\nThough PU learning is widely used in fraud detection\nand bioinformatics [7], it has also been applied to review spam\ndetection in NLP [ 14] and classifier learning from limited\nlabels [8]. Our work emphasizes the importance of prioritizing\nrare deception cases over more abundant truthful ones. Hybrid Architectures. Models that combine BERT with\nstructured or interpretable features have shown improved\ngeneralization and user trust [ 9]. PU-Lie follows this path\nby blending semantics with linguistics and domain-specific\nsignals. III. M ETHODOLOGY\nWe evaluate seven models for deception detection. Our best\nmodel, PU-Lie, uses the following components:\n\nA.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p3_c6",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 3,
      "chunk_index": 6,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 13130,
      "char_end": 14234,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p3_c5",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p3_c7",
      "semantic_coherence": 0.6664645671844482,
      "has_citations": true,
      "topic_cluster": 0
    },
    {
      "text": "Dataset\nThe Diplomacy dataset consists of 17,289 private messages\nfrom 12 complete games. Each instance includes rich game\nand message metadata. Key fields:\n\u2022 messages: Sequence of text messages in dialogue. \u2022 speakers, recipients: Player roles per message. \u2022 sender labels, receiver labels: Deception tags: true (lie),\nfalse (truth), NOANNOTATION. \u2022 game score, game score delta: Player scores and dif-\nferences. \u2022 seasons, years: Game timeline (e.g., Spring 1902).\n\n\u2022 absolute message index: The index the message is in\nthe entire game, across all dialogs\n\u2022 relative message index: The index of the message in\nthe current dialog\n\u2022 game id Unique game. \u2022 players: Involved players(Countries). Example \u2014 Truthful Message:\nTurkey: That sounds good to me. I\u2019ll move to defend\nagainst Italy while you move west. Example \u2014 Deceptive Message:\nItaly: We\u2019re friends, right? I believe every single\nmessage I\u2019ve sent you all game has been truth... The key challenge lies in identifying deceptive messages\n(\u02dc4.5%) amid mostly truthful exchanges.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p3_c7",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 3,
      "chunk_index": 7,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 14234,
      "char_end": 15269,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p3_c6",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p3_c8",
      "semantic_coherence": 0.37051278352737427,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "We address this by\ntreating unlabeled instances as a mix of positives and negatives\nunder PU learning, focusing our model design on maximizing\ndeceptive class detection performance. B. Proposed Methodology\nOur proposed system, PU-Lie, is a lightweight and in-\nterpretable model designed to detect deception in highly\nimbalanced diplomatic dialogues. The architecture combines\nfrozen BERT embeddings, handcrafted linguistic and game-\nspecific features, and a PU learning objective to optimize for\nrare but critical deceptive instances. Figure 1 illustrates the\noverall pipeline.\n\n1) Input Processing: All input messages from the Diplomacy\ndataset are passed through three parallel branches:\nBERT Tokenizer and Encoder: Messages are first tokenized\nand embedded using a frozen bert-base-uncased model to\nextract contextualized sentence-level representations. These em-\nbeddings are fixed during training to reduce model complexity. Linguistic Feature Extractor: In parallel, a set of handcrafted\nlinguistic features is computed. These include pronoun ratios,\nhedge word usage, assertiveness scores, and sentiment scores\n(using V ADER), which help interpret deception-related cues.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c8",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 4,
      "chunk_index": 8,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 15269,
      "char_end": 16447,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c7",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c9",
      "semantic_coherence": 0.5476856827735901,
      "has_citations": false,
      "topic_cluster": 0
    },
    {
      "text": "Game Feature Extractor: Game-related metadata such as\nseason, game score delta, and player roles are extracted to\ncapture strategic context relevant to deception. 2) FeatureNet and Fusion: The linguistic and game-specific\nfeatures are fed into a small feed-forward subnetwork (Fea-\ntureNet), which consists of a linear layer followed by ReLU\nactivation and dropout for regularization. The output of Fea-\ntureNet is then concatenated with the frozen BERT embeddings\nto form a fused representation combining deep semantics with\ninterpretable structure.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c9",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 4,
      "chunk_index": 9,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 16447,
      "char_end": 16997,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c8",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c10",
      "semantic_coherence": 0.5610401630401611,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "3) Classification and PU Learning: The fused representation\nis passed through a lightweight linear classifier to output a\nsingle logit value. Instead of using traditional binary cross-\nentropy, we employ a PU (Positive-Unlabeled) loss module\nthat estimates the classification risk using the known positive\nsamples (deceptive messages) and the unlabeled set, with a\nclass prior \u03c0 = 0.05. 4) Optimization: The model is trained end-to-end using\nAdamW optimizer with a learning rate of 1e-3 and batch size\nof 32 for 25 epochs.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c10",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 4,
      "chunk_index": 10,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 16998,
      "char_end": 17520,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c9",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c11",
      "semantic_coherence": 0.3097842335700989,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "Only the FeatureNet and classifier layers\nare updated during training, keeping BERT frozen, resulting in\na highly efficient model with only 1,345 trainable parameters. Fig. 1. Overview of PU-Lie model architecture combining BERT embeddings,\nlinguistic and game-specific features, and PU learning. IV. E XPERIMENTS\nIn this section, we conduct comprehensive experiments\nto evaluate PU-Lie against six alternative models on the\nDiplomacy deception detection task. We describe our evaluation\nprotocol, model settings, and present detailed analysis of results. A. Evaluation Protocol\nGiven the extreme class imbalance (only 4.5% deceptive\nmessages), we adopt macro F1-score as our primary evaluation\nmetric.\n\nMacro F1 gives equal importance to both deceptive\n(positive) and truthful (negative) classes, making it more reliable\nthan accuracy under skewed distributions. We also report",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c11",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 4,
      "chunk_index": 11,
      "section": "4.5% of these messages are labeled as deceptive, resulting in",
      "char_start": 17521,
      "char_end": 18399,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c10",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p4_c12",
      "semantic_coherence": 0.5006070733070374,
      "has_citations": false,
      "topic_cluster": 0
    },
    {
      "text": "MODEL PERFORMANCE ON DECEPTION DETECTION . PU-L IE OUTPERFORMS ALL BASELINES WHILE BEING SIGNIFICANTLY SMALLER , FASTER , AND MORE\nEFFICIENT .",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c12",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 5,
      "chunk_index": 12,
      "section": "TABLE I",
      "char_start": 30252,
      "char_end": 30394,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c11",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c13",
      "semantic_coherence": 0.5634994506835938,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "Model Macro F1 Trainable Params Training Time Inference Time Epochs\nTF-IDF + Logistic Regression 0.3900 1012 2 mins 10 secs -\nBERT + Power Embeddings + LSTM 0.4901 ( \u00b10.01) 2,300,000 18 mins 30 secs 10\nGNN with Graph Attention 0.5000 ( \u00b10.01) 1,101,954 22 mins 40 secs 10\nOversampled BERT + LSTM 0.5100 ( \u00b10.01) 2,300,000 19 mins 40 secs 10\nBERT + Linguistic + Game + LSTM 0.5453 ( \u00b10.02) 1,322,626 28 mins 40 secs 25\nBERT + Game Features + LSTM 0.5471 ( \u00b10.01) 1,180,994 25 mins 35 secs 25\nPU-Lie (Ours) 0.6000 ( \u00b10.01) 1,345 1.7 mins 5 secs 25\nstandard deviation across five runs with different seeds to\nensure robustness.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c13",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 5,
      "chunk_index": 13,
      "section": "TABLE I",
      "char_start": 30395,
      "char_end": 31019,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c12",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c14",
      "semantic_coherence": 0.32315489649772644,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "For PU-Lie, we apply precision-recall curve-based thresh-\nold tuning to better capture deceptive messages by maximizing\nrecall at an optimal precision. B. Models Evaluated\n\u2022 TF-IDF + Logistic Regression: Classical baseline using\nsparse features. Poor performance due to lack of context\n[15]. \u2022 BERT + Game Features + LSTM: Combines BERT\nwith in-game features and LSTM. Moderate F1 but\ncomputationally heavy. \u2022 BERT + Linguistic + Game + LSTM: Adds linguistic\nmarkers (e.g., pronouns, hedging) to the previous model. Slight F1 boost. \u2022 BERT + Power Embeddings + LSTM: Adds strategic\npower dynamics as embeddings.\n\nPerformance drops due\nto feature noise. \u2022 Oversampled BERT + LSTM: Uses naive oversampling\nof positive (deceptive) class. Slight improvement, but\noverfits. \u2022 GNN with Graph Attention: Represents players and\nmessages as a graph. Fails to generalize due to imbalance. \u2022 PU-Lie (Ours): Combines frozen BERT, handcrafted\nfeatures, and PU loss. Best performance with lowest\nparameter count. V. R ESULTS\nThe experimental results, highlighting the comparative\nperformance of all evaluated models, are comprehensively\npresented in Table I.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c14",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 5,
      "chunk_index": 14,
      "section": "TABLE I",
      "char_start": 31020,
      "char_end": 32164,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c13",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c15",
      "semantic_coherence": 0.6791436076164246,
      "has_citations": true,
      "topic_cluster": 0
    },
    {
      "text": "This table illustrates the macro F1\nscores, parameter counts, training time and inferencing time\ndemonstrating the effectiveness and efficiency of the proposed\nPU-Lie model. A. Inference from Model Comparison\nAlthough the TF-IDF + Logistic Regression model has\nslightly fewer trainable parameters than PU-Lie (1,012 vs.\n1,345) and both models exhibit comparable training and\ninference times (approximately 2 minutes and 10 seconds for\nTF-IDF + LR vs. 1.7 minutes and 5 seconds for PU-Lie), the\nPU-Lie model significantly outperforms it in terms of macro F1\nscore (0.60 vs. 0.39).",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c15",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 5,
      "chunk_index": 15,
      "section": "TABLE I",
      "char_start": 32164,
      "char_end": 32743,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c14",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c16",
      "semantic_coherence": 0.5003699064254761,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "This highlights that while both models are\nlightweight and efficient, PU-Lie captures deceptive patterns\nfar more effectively due to its integration of contextual BERT\nembeddings, interpretable linguistic features, and PU learning\noptimization. B. Ablation Studies\n\u2022 BERT + Game Features + LSTM: This model uses\nBERT embeddings, game context features, and a bi-\ndirectional LSTM to capture sequential dependencies. It performs better (F1 = 0.5471), showing the value of\ncombining deep language models with game dynamics. \u2022 BERT + Linguistic + Game + LSTM: Adds linguistic\nfeatures (e.g., pronouns, hedges) to the previous model.\n\nPerformance improves marginally (F1 = 0.5453), indi-\ncating that LSTMs may not effectively leverage shallow\nfeatures when trained jointly. \u2022 BERT + Power Embeddings + LSTM: Introduces hand-\ncrafted \u201cpower\u201d features reflecting strategic dominance or\ncontrol, but reduces performance (F1 = 0.4901), suggesting\nthese embeddings may be noisy or redundant. \u2022 Oversampled BERT + LSTM: Oversamples deceptive\nmessages to balance the dataset before training. Perfor-\nmance (F1 = 0.5100) is better than the power model but\nstill below PU-Lie, indicating that naive balancing does\nnot solve the core problem.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c16",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 5,
      "chunk_index": 16,
      "section": "TABLE I",
      "char_start": 32744,
      "char_end": 33971,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c15",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c17",
      "semantic_coherence": 0.47805485129356384,
      "has_citations": false,
      "topic_cluster": 0
    },
    {
      "text": "\u2022 GNN with Graph Attention: Models player relationships\nand game structure as a graph. Despite its sophistication,\nthe model achieves only 0.50 F1, likely due to overfitting\non sparse deception data. \u2022 PU-Lie (Ours): Combines frozen BERT embeddings,\nlinguistic + game features, and PU loss. It achieves the\nhighest macro F1 of 0.60 with only 1,345 parameters,\ndemonstrating superior generalization and efficiency. VI. D ISCUSSION\nPU-Lie demonstrates strong performance and efficiency\nunder imbalanced settings. It avoids majority collapse and\nenhances interpretability.\n\nFocus on Deception: In deception detection, the cost of\nmissing a lie is typically higher than a false alarm. Our\nuse of PU learning reflects this bias by focusing on better\n\nidentifying deceptive messages and tailoring the architecture\nfor this asymmetric objective. Efficiency and Deployment: With only 1,345 parameters,\nPU-Lie is ideal for deployment in edge environments or real-\ntime settings. Limitations: PU-Lie assumes a static class prior. Cultural\nnuances or shifts in discourse style may not be captured. Future work may explore dynamic priors and cross-domain\ntransferability. VII.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c17",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 5,
      "chunk_index": 17,
      "section": "TABLE I",
      "char_start": 33971,
      "char_end": 35135,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c16",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c18",
      "semantic_coherence": 0.7591683268547058,
      "has_citations": false,
      "topic_cluster": 0
    },
    {
      "text": "C ONCLUSION\nWe present PU-Lie, a novel, interpretable, and lightweight\nmodel for deception detection in imbalanced strategic dialogue. It combines frozen BERT embeddings with handcrafted features\nand a PU learning framework to outperform heavy baselines\nusing a fraction of the parameters. In addition to its strong\nperformance, PU-Lie is highly efficient, requiring significantly\nfewer computational resources and enabling faster inference\nand deployment in low-resource environments. Our results show\nthat explicitly targeting deceptive message detection\u2014rather\nthan treating all messages equally\u2014leads to more robust,\ninterpretable, and generalizable models. Future work includes\nmultilingual extensions, dynamic class prior estimation, and\nreal-time deception detection in interactive settings.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c18",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 5,
      "chunk_index": 18,
      "section": "TABLE I",
      "char_start": 35135,
      "char_end": 35933,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c17",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c19",
      "semantic_coherence": 0.7774444222450256,
      "has_citations": false,
      "topic_cluster": 0
    },
    {
      "text": "[1] J. T. Hancock, L. E. Curry, S. Goorha, and M. Woodworth, \u201cLying for\nmoney: How people lie differently when they are paid more,\u201d Personality\nand Social Psychology Bulletin , vol. 34, no. 4, pp. 536\u2013548, 2008. [2] M. Ott, Y . Choi, C. Cardie, and J. T. Hancock, \u201cFinding deceptive opinion\nspam by any stretch of the imagination,\u201d in Proceedings of the 49th\nAnnual Meeting of the Association for Computational Linguistics , 2011. [3] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, \u201cBert: Pre-training\nof deep bidirectional transformers for language understanding,\u201d NAACL-\nHLT, 2019. [4] N.\n\nRuchansky, S. Seo, and Y . Liu, \u201cCsi: A hybrid deep model for fake\nnews detection,\u201d in Proceedings of the 2017 ACM on Conference on\nInformation and Knowledge Management , 2017, pp. 797\u2013806. [5] M. V ollmer and S. Adali, \u201cLinguistic deception detection using neural\nnetworks,\u201d in Proceedings of the 2021 Conference on Empirical Methods\nin Natural Language Processing (EMNLP) , 2021. [6] T.-Y . Lin, P. Goyal, R. Girshick, K. He, and P. Doll \u00b4ar, \u201cFocal loss\nfor dense object detection,\u201d in Proceedings of the IEEE International\nConference on Computer Vision , 2017, pp. 2980\u20132988. [7] J.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c19",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 5,
      "chunk_index": 19,
      "section": "REFERENCES",
      "char_start": 41632,
      "char_end": 42813,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c18",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c20",
      "semantic_coherence": 0.6707226037979126,
      "has_citations": true,
      "topic_cluster": 0
    },
    {
      "text": "Bekker and J. Davis, \u201cLearning from positive and unlabeled data: A\nsurvey,\u201d Machine Learning, vol. 109, pp. 719\u2013760, 2020. [8] C. Elkan and K. Noto, \u201cLearning classifiers from only positive and\nunlabeled data,\u201d Proceedings of the 14th ACM SIGKDD international\nconference on Knowledge discovery and data mining , pp. 213\u2013220, 2008. [9] N. F. Rajani, B. McCann, C. Xiong, and R. Socher, \u201cExplain yourself! leveraging language models for commonsense reasoning,\u201d in Proceedings\nof the 57th Annual Meeting of the Association for Computational\nLinguistics, 2019. [10] P. Veli \u02c7ckovi\u00b4c, G. Cucurull, A. Casanova, A. Romero, P. Lio, and\nY .\n\nBengio, \u201cGraph attention networks,\u201d in International Conference\non Learning Representations (ICLR) , 2018. [11] T. Zhang, R. Xu, Q. Zhang, and Z. Wu, \u201cStructure-aware dialogue state\ntracking,\u201d in Proceedings of the 59th Annual Meeting of the Association\nfor Computational Linguistics (ACL) , 2021. [12] S. Feng, R. Banerjee, and Y . Choi, \u201cSyntactic stylometry for deception\ndetection,\u201d ACL, 2012. [13] N. V . Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer,\n\u201cSmote: Synthetic minority over-sampling technique,\u201d Journal of artificial\nintelligence research, vol. 16, pp. 321\u2013357, 2002. [14] F. Li, M. Huang, Y . Yang, and X.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c20",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 5,
      "chunk_index": 20,
      "section": "REFERENCES",
      "char_start": 42813,
      "char_end": 44077,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c19",
      "next_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c21",
      "semantic_coherence": 0.43361616134643555,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "Zhu, \u201cLearning to identify review spam,\u201d\nin Proceedings of the Twenty-Second international joint conference on\nArtificial Intelligence, 2011. [15] D. Zhou, O. Bousquet, T. Lal, J. Weston, and B. Sch \u00a8olkopf, \u201cLearning\nwith local and global consistency,\u201d in Advances in neural information\nprocessing systems, 2004.",
      "chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c21",
      "source_file": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection.pdf",
      "page": 5,
      "chunk_index": 21,
      "section": "REFERENCES",
      "char_start": 44077,
      "char_end": 44390,
      "prev_chunk_id": "Choudhury_2024_PU_Lie_Lightweight_Deception_Detection_p5_c20",
      "next_chunk_id": null,
      "semantic_coherence": 0.431328684091568,
      "has_citations": true,
      "topic_cluster": -1
    }
  ]
}