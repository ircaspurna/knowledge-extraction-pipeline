{
  "text": "RESEA RCH ARTICL E\nDeception detection with machine learning: A\nsystematic review and statistical analysis\nAlex Sebasti\u00e3o Consta \u02c6 ncio\nID\n1\u262f\n*, Denise Fukumi Tsunoda\n1\u262f\n, Helena de Fa \u00b4 tima\nNunes Silva\n1\u2021\n, Jocelaine Martins da Silveira\n2\u2021\n, Deborah Ribeiro Carvalho\n3\u2021\n1 PPGGI, Universidad e Federal do Parana \u00b4 , Curitiba, State of Parana \u00b4 , Brazil, 2 PPGPSI, Univers idade\nFederal do Parana \u00b4 , Curitiba, State of Parana \u00b4 , Brazil, 3 PPGTS, Pontif\u0131 \u00b4 cia Univers idade Cato \u00b4 lica do Parana \u00b4 ,\nCuritiba, State of Parana \u00b4 , Brazil\n\u262f These authors contribu ted equally to this work.\n\u2021 HFNS, JMS, and DRC also contributed equall y to this work.\n* alex.cons tancio@ufpr .br\nAbstract\nSeveral studies applying Machine Learning to deception detection have been published in\nthe last decade. A rich and complex set of settings, approaches, theories, and results is now\navailable. Therefore, one may find it difficult to identify trends, successful paths, gaps, and\nopportunities for contribution. The present literature review aims to provide the state of\nresearch regarding deception detection with Machine Learning. We followed the PRISMA\nprotocol and retrieved 648 articles from ACM Digital Library, IEEE Xplore, Scopus, and Web\nof Science. 540 of them were screened (108 were duplicates). A final corpus of 81 docu-\nments has been summarized as mind maps. Metadata was extracted and has been\nencoded as Python dictionaries to support a statistical analysis scripted in Python program-\nming language, and available as a collection of Jupyter Lab Notebooks in a GitHub reposi-\ntory. All are available as Jupyter Lab Notebooks. Neural Networks, Support Vector\nMachines, Random Forest, Decision Tree and K-nearest Neighbor are the five most\nexplored techniques. The studies report a detection performance ranging from 51% to\n100%, with 19 works reaching accuracy rate above 0.9. Monomodal, Bimodal, and Multi-\nmodal approaches were exploited and achieved various accuracy levels for detection.\nBimodal and Multimodal approaches have become a trend over Monomodal ones, although\nthere are high-performance examples of the latter. Studies that exploit language and linguis-\ntic features, 75% are dedicated to English. The findings include observations of the follow-\ning: language and culture, emotional features, psychological traits, cognitive load, facial\ncues, complexity , performance, and Machine Learning topics. We also present a dataset\nbenchmark. Main conclusions are that labeled datasets from real-life data are scarce. Also,\nthere is still room for new approaches for deception detection with Machine Learning, espe-\ncially if focused on languages and cultures other than English-based. Further research\nwould greatly contribute by providing new labeled and multimodal datasets for deception\ndetection, both for English and other languages.\nPLOS ONE\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 1 / 31\na1111111111\na1111111111\na1111111111\na1111111111\na1111111111\nOPEN ACCESS\nCitation: Consta \u02c6 ncio AS, Tsunoda DF, Silva HdFN,\nSilveira JMd, Carvalho DR (2023) Deception\ndetection with machine learning: A systematic\nreview and statistical analysis . PLoS ONE 18(2):\ne0281323. https://d oi.org/10.1371/j ournal.\npone.028132 3\nEditor: Muhammad Fazal Ijaz, Sejong University,\nREPUBLIC OF KOREA\nReceived: June 15, 2022\nAccepted: January 20, 2023\nPublished: February 9, 2023\nCopyright: \u00a9 2023 Consta \u02c6 ncio et al. This is an open\naccess article distributed under the terms of the\nCreative Commons Attribution License, which\npermits unrestricte d use, distribu tion, and\nreproduction in any medium, provided the original\nauthor and source are credited.\nData Availabilit y Statement: All Jupyter Lab\nNotebooks and BiblioAlly database files are\navailable on the GitHub repository access ible at\nhttps://github .com/gambi t4348/deceptio n-\ndetection-re view-2022.\nFunding: The author(s) received no specific\nfunding for this work.\nCompeting interests : The authors have declared\nthat no competing interests exist.\n\nIntroduction\nWe aim to find out which Machine Learning techniques perform best for automatic deception\ndetection, what kind of data they process, what is the source of that data, and what theoretical\nframework they have used. We also seek to understand their limitations and merits, and what\nremains to be explored.\nTherefore, this paper is not about Artificial Intelligence, Machine Learning, or deception\ndetection. Instead, it is a literature review on deception detection with Machine Learning. Our\nintention is not to go deep into either deception detection or Machine Learning. Instead, our\nfocus is on selecting and scrutinizing research papers on the application of Machine Learning\nfor deception detection.\nFor this study, we define both \u201cdeceiving\u201d and\u201dlying\u201d as the intentional act of making the\ninterlocutor believe in something the deceiver considers false [1]; it is a conscious and deliber-\nated act, perpetrated by the deceiver [2]. However, a false information believed to be true by\nthe emitter is not considered deceptive.\nLying is a frequent and pervasive social phenomenon [3]. While some forms may be\naccepted as a \u201csocial lubricant\u201d [4], others are socially harmful. Telling (and being told) lies is\nfrequent but perceiving them is a major challenge for most people. The average person has a\nlie detection rate around 54% [5, 6], rarely reaching 60%, and sometimes falling below 50%\n[7].\nNevertheless, some individuals show a remarkable ability for spotting deceptions, with a\ndetection accuracy above 90%. Referred to as \u201cWizards of deception detection\u201d [5], these indi-\nviduals demonstrate that lies can be detected. Such \u201cwizards\u201d, however, are not numerous.\nMachine Learning has been successfully applied to a large number of fields and functions,\nsuch as document classification, computer vision, natural language processing, protein struc-\nture prediction, fraud and malware detection [8], medical diagnosis and data privacy [9], net-\nwork and data transmission security [10], intrusion detection [11], generative molecular\ndesign [12], and recommendation systems, among others [13]. Also, it offers a vast set of tech-\nniques, providing several opportunities to approach various problems. Seeing Machine Learn-\ning applied to deception detection is not surprising.\nWe noticed many studies on deception detection aided by Machine Learning have been\npublished in the last decade. Those report different approaches and results, a rich and bulky\ncorpus of knowledge is available. The results, however, suffer from large variance, with a diver-\nsity of settings, techniques, complexities, and strategies based on several theoretical frame-\nworks. Identifying trends, gaps, and research opportunities may be challenging.\nDue to the diversity of studies and the difficulty of establishing a general state of technology\non deception detection with Machine Learning, we felt stimulated to formulate the following\nresearch questions: a) What are the best-performing Machine Learning techniques applied to\nautomatic deception detection? b) What are the datasets and features they consume? c) What\nlevel of performance have they reached recently?\nThis literature review aims to answer those questions and give a comprehensive overview of\nthe application of Machine Learning for deception detection. We intend to report what\nresearchers have exploited as techniques and approaches, their difficulties, what kind of data\nthey have consumed, and what performance levels they have achieved.\nTo the best of our knowledge, this is the first literature review that scrutinizes the applica-\ntion of Machine Learning for deception detection. Trends, gaps, difficulties, results, and\nopportunities are highlighted to stimulate further studies and new developments in the area.\nOur main contributions are as follows:\n1. To identify the most frequent and performant Machine Learning techniques;\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 2 / 31\n\n2. To enumerate the most explored feature modalities;\n3. To compare the studies\u2019 approaches with theoretical frameworks of deception detection;\n4. To summarize articles in the form of mind maps;\n5. To make the whole history and statistical analysis available as Jupyter Lab Notebooks.\nThe rest of this report is organized as follows: a) the \u201cTheoretical background\u201d section pres-\nents some basic knowledge on deception detection and Machine Learning; b) the \u201cMaterials\nand Methods\u201d section presents the research process in detail; c) the \u201cData availability\u201d section\ndescribes where all the data is located; d) the \u201cAssessment of quality and the risk of bias\u201d sec-\ntion describes the two tools used to asses quality and risk of bias in this report; the \u201cResults\u201d\nsection presents the selected corpus and the answer to the research questions; e) the \u201cDiscus-\nsion\u201d section comments various thematic dimensions emerged from the selected corpus; f) the\n\u201cCurrent state and further research\u201d section presents a general conclusion regarding the state\nof the field, and presents some opportunities for future work; g) the \u201cLimitations and further\nwork\u201d section presents the limitations of this research and proposals for future extensions; h)\nthe \u201cConclusions\u201d section presents our final words and reflections in light of the findings.\nTheoretical background\nThe following sections present some background on the main topics explored in this review.\nDeception detection. Deception detection is the act of deciding whether a certain com-\nmunication carries the truth or not. It is an active and evidence-driven inference process [14].\nHigh-stakes deceptions are believed to induce behavioral and physiological changes in the\ndeceiver, yielding more evident indicators of lie-telling [1]. The task even more challenging\nbecause no clue alone is an indisputable predictor of deception [2, 4, 15].\nThe behavioral and physiological changes experienced by the deceiver work as deception\ncues [1, 2, 16]. An observer that notices these cues may be enabled to detect an attempt of decep-\ntion. Such behavioral changes are what human lie detectors observe to make their judgment.\nDeception cues can be verbal (effects on the deceiver\u2019s speech) and non-verbal (impact on\nhow the deceiver speaks and acts). The different sources of cues are usually called modalities\nor channels. For instance, the cues identified from a deceiver\u2019s voice are said to be from the\nvocal channel or to belong to the vocal modality.\nExamples of non-verbal cues include gestures such as self-adaptors (touching one\u2019s own\nbody, face, or hair) [4], manipulators (pinching, picking, scratching) [2], emblems (gestures\nthat replace words) [2], or illustrators (gestures that accompany speech) [2, 4].\nThe need for better ways to detect deceptions stimulated the creation of aiding technology\nto increase the detection accuracy. The most famous example is the polygraph, introduced in\nthe Berkeley Police Department by John Larson [17], in 1921. The current polygraph models\ncan monitor several physiological responses from a subject and require a preliminary calibra-\ntion step to establish a baseline for the operator.\nIt is essential to understand that the polygraph does not detect lies. Instead, it shows physio-\nlogical alterations related to emotions [2]. It\u2019s the operator that interprets and decides whether\na given message is sincere or not. There are accounts of false positives who have been exoner-\nated of criminal charges after further investigations proved the polygraph test mistakenly\ndetected a deception [2]. Due to the polygraph\u2019s limitations, other technological opportunities\nbegan to be considered. Positive results achieved by Machine Learning in several fields over\nthe last 20 years worked to stimulate new research to respond to the challenges of deception\ndetection.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 3 / 31\n\nMachine Learning. Machine Learning is a branch of Artificial Intelligence that allows\ncomputers to learn from data and acquire skills to work on a task without being programmed\nexplicitly for it [18]. It is a multi-disciplinary field that includes contributions from Psychol-\nogy, Neuroscience, Control Theory, and Philosophy, to name a few [19].\nBy consuming spreadsheet-like structures (datasets), Machine Learning algorithms produce\na so-called model, a general representation of the patterns in data. Each row of the dataset is an\nexample or individual and each column is a feature [13, 20].\nIt is usual to separate a part of the dataset for training and another for testing. Training is\nthe phase of producing the model from the data, whereas testing consists of measuring the\nmodel\u2019s performance and generality.\nMachine Learning can be applied to many different tasks, such as Classification, Regression,\nClustering, Association Rules, and Anomaly Detection. For each task, different techniques can\nachieve different performance levels.\nClassification tasks rely on algorithms that assign a given class (or label) to a specific data\nexample. Those classes are a limited number of categorical values [19]. So, they are not contin-\nuous values (while features can be).\nModels for Classification problems (classifiers) frequently use a so-called supervised learn-\ning process. Each training data example already has a label (or class) assigned [21]. The\nMachine Learning algorithm will produce a model that relates specific examples to certain\nclasses to predict the class for a new, unseen, data example. That\u2019s why it is often also called a\npredictive model.\nPredictive models are useful in many problems, such as price prediction, risk assessment,\nmedical diagnosis, document classification [22], spam filtering, image classification, fraud\ndetection, churn analysis, risk analysis [21], among others. For detection purposes, Classifica-\ntion models can be used for detecting diseases like Alzheimer\u2019s disease [23] or skin pathologies\n[24], detecting physiological alterations [25, 26] and even traffic accidents [27].\nAlternatively, unsupervised or self-supervised learning happens when the model training\ndoes not require labeled data [20].\nThere are several Machine Learning algorithms based on different theoretical frameworks\nand strategies [19], such as Decision Trees [28], Na\u00efve Bayes [29], Support Vector Machines\n[30], K-Means [31], Random Forests [32] and Neural Networks [33].\nNo matter the problem, the area, or the algorithm, however, it is constant that the quality of\ndata for training the models plays a crucial role in the success of any Machine Learning\nproject.\nDeep Learning. Deep Learning is a kind of Machine Learning that represents knowledge\nas a hierarchical structure, building complex and specific representations over simpler and\nbroader ones [20].\nConventional Machine Learning methods are severely impacted by the features they con-\nsume. Wrong features may lead to incorrect or undesired results, which promotes an entire\narea of study known as feature engineering. However, Deep Learning methods can detect\nwhich features are relevant in raw data and extract them instead of others [20].\nDeep Learning models are usually very complex, composed of multiple layers of representa-\ntions, easily ranging from dozens to hundreds. Such stacked layers store the hierarchical repre-\nsentations that allow the model to encode complex data relationships usually found in\nchallenging problems [34].\nWhile Deep Learning has achieved remarkable results in many areas, it relies on large\namounts of data for training. Furthermore, the number of parameters that make up a Deep\nLearning model can reach millions, which makes the training process extraordinarily demand-\ning and may require the power of many Graphic Processing Units (GPUs) for several days.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 4 / 31\n\nMaterials and methods\nWe decided to store the history of our process in Jupyter Lab Notebooks. Those are digital doc-\numents that store and run Python code. Such notebooks: a) record our Research protocol,\nfound in S3 File (Definition Jupyter Notebook); b) present the steps for selecting the corpus,\nfound in S4 File (Corpus collection Jupyter Notebook); c) present the steps for analyzing the\ncorpus, found in S5 File (Corpus analysis Jupyter Notebook); d) present all the steps for pro-\ncessing the extracted metadata, found in S6 File (Statistical analysis Jupyter Notebook) and; e)\nshow all the mind maps built for each document in the selected corpus, found in S7 File (Mind\nmaps Jupyter Notebook). Our research is reproducible, and its entire history is preserved.\nThis study is both a qualitative and quantitative review. An analysis consisting of statistical\nevaluations of the selected articles [35] comprises the quantitative portion and was performed\nto describe studies from a numerical and objective perspective.\nAll the metadata was extracted directly from the selected corpus and no value was, by any\nmeans, inferred or interpreted. Sometimes, the total number of features was summed when the\ntext didn\u2019t present it, but all the primitive values were there. Such metadata describes the\nsource of training data, training strategy, Machine Learning methods, dataset sizes, predictors\nexploited, cues complexity, modality cardinality, performance levels, and performance metrics.\nSuch an analysis is not a meta-analysis since we designed the research to present a broad\npicture, not limited to evaluating only the final performance reported. The wide spectrum of\nfactors stored into the metadata from each article naturally led to a high level of heterogeneity,\nwhich prevented any attempt to combine them.\nHowever, the statistics rendered a rich, multidimensional profile of the topic and author\u2019s\napproaches, highlighting their choices, limitations, expectations, and results. Those can be\nfound in S6 File (Statistical analysis Jupyter Notebook).\nAs for the qualitative portion, our findings are discussed in light of the knowledge about\ndeception detection techniques from a psychological perspective. Such discussions include\nthemes that emerged from the selected corpus. They are more a finding than a choice and are\nall presented in the \u201cDiscussions\u201d section.\nThe established design, supporting tools, research restrictions, and other details are pre-\nsented in the following sections.\nResearch goals and inclusion criteria\nThe main goal of this systematic review is to retrieve and study the most comprehensive collec-\ntion of scientific production about Machine Learning applied to deception detection in our\npower. That allowed us to understand the current trends, difficulties, approaches, results, and\ngeneral state of the field.\nOur protocol and selection criteria best balances both our goals and limitations. We believe\nwe could capture the studies that best met our research goals, regardless of the technique, strat-\negy, or approach decisions.\nRegarding PICO (Population-Intervention-Com parison-Outcome) components, this\nresearch design is as follows: a) Population: studies on deception detection; b) Intervention:\nMachine Learning techniques; c) Comparator: none; Outcome: performance level.\nAccording to the research interests, we enforced the following selection restrictions: a) only\nstudies that address deception detection; b) only studies that exploit Machine Learning; c) only\nstudies that clearly state what data features were consumed; d) only studies that report a per-\nformance level; e) only methods and techniques that consume data from non-invasive sources.\nBy non-invasive, we mean methods that either do not touch the subjects or observe them\nby a device less mobile than a regular computer (e.g., a Magnetic Resonance Image machine,\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 5 / 31\n\nMRI). However, studies combining skin-level invasive, and non-invasive approaches were\nselected.\nThe period ranged from 2011 to 2021, inclusive, as we consider such years sufficiently\nrecent for our purposes.\nSupporting tools\nWe exploited the following free resources to improve productivity, precision, and safety:\n1. The Python programming language, chosen due to its familiarity to the authors and other\nresearch groups;\n2. Python packages Pandas and MatPlotLib, for statistical analysis since they are richly fea-\ntured and usually applied in data analysis;\n3. Jupyter Lab, as a platform to run the statistical analysis scripts and generate charts, tables,\nand a process history;\n4. FreeMind, to build summary mind maps from the deep screened papers.\nIn addition, BiblioAlly, a computer program written in Python, was built by one of the\nauthors, because bibliographic managers, such as Mendeley, do not always interpret biblio-\ngraphic citation files correctly, thus requiring some extra and time-consuming correction\nwork. Moreover, they do not offer features to store metadata nor manage, track, and support\nthe research workflow. In our case, such citation files were BibTeX files.\nBiblioAlly can handle the differences existing in BibTeX files, manage and track the steps of\nthe research protocol, and store the extracted metadata. It greatly optimized the entire process.\nBiblioAlly. is free and available at GitHub (http://github.com/ga mbit4348/biblioally) and at\nthe Python Package Index (PyPI).\nResearch protocol\nOur research protocol is as follows:\n1. Run queries on scientific document databases;\n2. Export results as BibTeX files;\n3. Import all BibTeX files into BiblioAlly;\n4. Manually detect duplications not detected by BiblioAlly during import;\n5. Pre-select articles by shallow screening:\na. Read title, keywords, and abstract for each paper;\nb. Reject studies that violate research restrictions;\n6. Retrieve the full text of pre-selected documents;\n7. Select articles by deep screening:\na. Read full text;\nb. Reject studies that violate research restrictions;\n8. Extract relevant data from accepted documents:\na. Build FreeMind mental maps as summaries for the articles;\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 6 / 31\n\nb. Store the metadata in BiblioAlly;\n9. Perform a statistical analysis and generate charts and tables.\nThe protocol worked as a roadmap so the process can be rigorously and safely replicated.\nSearch strategy\nDue to previous experience with literature reviews, we expanded our search space by running\nqueries on four different scientific search engines: Web of Science, Scopus, ACM Digital\nLibrary, and IEEE Xplore.\nWe ran two rounds of search. The first one was on March 2\nnd\n, 2021, and returned studies\npublished from 2010 to 2020. The second run was on May 5\nth\n, 2022, and returned papers pub-\nlished in 2021. The year 2010 returned no papers that met the research protocol, therefore the\nperiod of interest is 2011\u20132021.\nAll queries were run using the syntax of each scientific search engine. As an additional filter,\nthe period of interest was limited to 2010\u20132020 and 2021, depending on the run, as shown in\nTable 1.\nData extraction\nTo perform the analysis with Pandas and MatPlotLib, the extracted metadata was encoded as\nPython dictionaries:\n1. document_id: the document id in the BiblioAlly database;\n2. methods: list of methods and tools, each item described as:\na. classifier: the classification algorithm in terms of:\nkind: when applicable, the sub-category of the method;\nimplementation: software, package or library that provided the algorithm;\ntraining: training method;\nTable 1. Search queries issued to different academ ic search engines.\nSearch engine Query strategy\nWeb of Science ((\"deception detection\" OR \"lie detection\") AND (\"machine\nlearning\" OR \"artificial intelligence\"))\nRefined by: Publication Years: (2021 OR 2020 OR 2019 OR 2018 OR 2017 OR\n2016 OR 2015 OR 2014 OR 2013 OR 2012 OR 2011)\nScopus TITLE-ABS-KEY ((\"deception detection\" OR \"lie detection\") AND\n(\"machine learning\" OR \"artificial intelligence\")) AND (LIMIT-TO\n(PUBYEAR, 2021) OR LIMIT-TO (PUBYEAR, 2020) OR LIMIT-TO\n(PUBYEAR, 2019) OR LIMIT-TO (PUBYEAR, 2018) OR LIMIT-TO\n(PUBYEAR, 2017) OR LIMIT-TO (PUBYEAR, 2016) OR LIMIT-TO\n(PUBYEAR, 2015) OR LIMIT-TO (PUBYEAR, 2014) OR LIMIT-TO\n(PUBYEAR, 2013) OR LIMIT-TO (PUBYEAR, 2012) OR LIMIT-TO\n(PUBYEAR, 2011))\nACM Digital\nLibrary\n[All: \"deception detection\"] OR [All: \"lie detection\"] AND\n[Publication Date: (01/01/2011 TO 12/31/2021)]\nIEEE Xplore ((\"All Metadata\": \"deception detection\") OR \"All Metadata\": \"lie\ndeception\")\nFilters Applied: 2011\u20132021\nSource: The authors (2022)\nEach scientific database allows the inclusion of extra metadata during the export to BibTeX format files. We included\nall these extra metadata.\nhttps://d oi.org/10.1371/j ournal.pon e.0281323.t00 1\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 7 / 31\n\nperformance: classification performance as:\n1. kind: the performance measure;\n2. value: the performance level;\nb. support: supporting tool for generic purposes;\n3. dataset: description of the dataset used in the study:\na. public: True indicates a freely accessible dataset, False the opposite;\nb. mock: True indicates a dataset collected from some fabricated setting, False indicates\ndata collected from real-life circumstances;\nc. name: name of the dataset, if any;\nd. size: number of dataset rows;\ne. origin: source of the data;\nf. target: labels used for the target attribute;\ng. features: list of feature kinds that make up the dataset:\nkind: the kind of detection cue features;\ndimensions: the number of features;\ncomponents: list of feature components;\nlanguage: list of languages, when applicable;\ntool: list of tools, when applicable;\n4. notes: textual notes about the study;\n5. mindmap: file name of the mind map document.\nThe dictionaries are readable by non-pythonists, provided a short explanation is given.\nData access\nFor transparency, we made available all data collected and encoded in this research in a GitHub\nrepository (http://github.com/gambit4348/dece ption-detection-review-2021). The Jupyter Lab\nNotebooks work as history for whole process. The BibTeX files and the BiblioAlly database can\nbe used under the MIT License and are also available. FreeMind documents are also available.\nFor convenience, we included those Jupyter Lab Notebooks as additional documents of this\nreview as Notebook 1 (Definition), Notebook 2 (Corpus collection), Notebook 3 (Corpus anal-\nysis), Notebook 4 (Statistical analysis), and Notebook 5 (Mindmaps) as PDF (Portable Docu-\nment Format) files.\nNot all the articles selected for the review were under open access, so we decided not to\nmake any available to avoid any copyright violations.\nAssessment of quality and the risk of bias\nThe AMSTAR-2 (A MeaSurement Tool to Assess systematic Reviews) tool [36] (https://\namstar.ca/Amstar_Checklist.ph p) was filled in to assess the quality parameters of this review.\nThe assessment report is available in S1 File.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 8 / 31\n\nAdditionally, an Excel spreadsheet was built and filled in to implement the PROBAST\n(Prediction model Risk Of Bias Assessment Tool) [37] assessment of the risk of bias (http://\nwww.probast.org). The PROBAST model provides 20 questions across 4 domains (partici-\npants, predictors, outcome, and analysis) that produce individual risk of bias and applicabil-\nity for each document of the review corpus. Such a spreadsheet file can also be accessed in\nthe S2 File.\nResults\nOur main goal is to comprehensively understand of the state of research regarding deception\ndetection with Machine Learning. To do so, we surveyed, studied, and selected a collection of\n81 documents out of 648 retrieved from four scientific databases. We report our findings in\nboth quantitative and qualitative fashions.\nFrom a quantitative perspective, we gathered a rich set of metadata to produce many charts\nand tables. Those numerically and objectively describe all the papers in the selected corpus (S5\nand S6 Files).\nFrom a corpus standpoint, a particular Jupyter Lab Notebook (S5 File) presents several\ncharts and tables.\nWe offer a specific Jupyter Lab Notebook (S6 File) that renders charts and tables that go\ndeep into research features (author decisions on how they approached the deception detection\nproblem) and what kind of Machine Learning strategies were chosen to respond to the\nresearch challenges. Such a Jupyter Lab Notebook exposes the performance levels reported as\nboxplots.\nAll those Jupyter Lab Notebooks can be found at GitHub. Here we present only the discus-\nsion of our findings, as we consider that our greatest contribution.\nFrom the qualitative perspective, we interpreted the statistical findings according to some\ntheoretical frameworks on deception detection [2, 4, 5]. We discuss how the authors\u2019\napproaches align to those frameworks, where they agree and don\u2019t, and what is still to be done.\nAll those comments can be found in the \u201cDiscussion\u201d section.\nWe have the following answers to the research questions:\na) What are the best performing Machine Learning techniques applied to automatic decep-\ntion detection? The Machine Learning techniques that best performed were Decision\nTrees, Gradient Boosting, Neural Networks, Multi-view learning, Random Forest, and Sup-\nport Vector Machines (SVM).\nb) What datasets and features do they consume? Most studies trained their classifiers with\nmock data, but the adoption of real-life data is increasing; features include verbal and non-\nverbal cues, mainly facial expressions, gestures, body temperature, prosodic and vocal fea-\ntures, and linguistic patterns; 117 different kinds of features were exploited as deception\ncues, distributed in nine modalities.\nc) What performance level have they recently achieved? Performance was measured\nmostly by accuracy, ranging from 0.51 to 1.0; other performance metrics were\nF1-score, Area Under the Curve (AUC), Unweighted Average Recall (UAR), Recall, and\nPrecision.\nBesides, deception detection was treated as a binary classification problem, except for one\ncase. Many studies were dedicated to a single modality, but multimodal studies seem to\nbecome a trend.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 9 / 31\n\nDistribution of retrieved documents\nThe PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) flow-\nchart that summarizes the building of the review corpus can be seen in Fig 1. The exclusion\nreasons for 459 documents are shown in Fig 2.\nWe drawn mind map summaries from the full reading of the selected documents, as well as\nwe extracted metadata especially intended for statistical analysis.\nThe selected documents\nTable 2 contains the list of all 81 selected documents. It can be used as a summary for the\nreview. The table is sorted by descending performance and presents the best-performing\nFig 1. PRISMA flowchart . This PRISMA flowchart presents the main steps of literature selection, deduplicati on, shallow and deep screening, until the\nfinal collection is reached. Each step displays the amount of docume nts selected so far. Source: The authors (2022).\nhttps://doi.o rg/10.1371/j ournal.pone .0281323.g001\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 10 / 31\n\ntechnique (in some cases, more than one was reported) with the highest performance metric\nin the first 19 rows (again, in some cases more than one was reported).\nHowever, the datasets and experiment setups are too diverse to be compared. Therefore, a\ndirect benchmark of the studies\u2019 performances is not reasonable. We include them here as\nanother feature of those studies, but we do not claim that the specific research that achieved a\nhigher accuracy than other is better. Those performance measures do not work here as a scale\nof success when approaching the problem, nor do they indicate that a particular approach is\nbetter than other. They can work, at best, as a baseline for further research designed under the\nsame conditions.\nThe 19 studies that achieved accuracy above 0.9 show their title in bold. The threshold, 0.9,\nwas chosen because it is the one Ekman considered as the accuracy level of distinctively per-\nforming lie-catchers [5].\nHowever, we stress that a particular study reporting accuracy equals or above 0.9 is not\nequivalent to a highly accurate human deception detector. Human lie-catchers show their\nskills in very diverse situations and outside of any controlled environment. The conditions\nthey are subjected to are far more complex than the ones Machine Learning solutions are at\nthis moment.\nWe only decided to use 0.9 as threshold here because Ekman considered that as an indicator\nof high-standard performance.\nDiscussion\nAs our contribution to the field, we present a discussion that unfolds in several themes (or\ndimensions) we consider suitable. Those themes were not chosen. Rather, they arise from the\nselected documents and represent a general summary of all the efforts analyzed. Those themes\nare findings themselves. They outline the main topics present in the selected studies regarding\nthe theoretical foundations of deception detection. Authors attempted these approaches to\nanswer to the deception detection problem.\nOur goal is to present an abstract notion of the state of each of those dimensions so we\ncould give researchers an insight about each theme. We hope that the following sections will\nFig 2. Rejectio n reasons. Papers that did not meet our selection criteria were rejected. The rejection reasons presented are those recorded for each\narticle during the screening steps. This bar chart presents all those reasons and their frequency. Source: The authors (2022).\nhttps://doi.o rg/10.1371/j ournal.pone .0281323.g002\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 11 / 31\n\nTable 2. List of all 81 selected docum ents.\nTitle Technique\n[2021] Use of Machine Learning for Deceptio n Detection from Spectral\nand Cepstral Features of Speech Signals [38]\nNeural Network / Accuracy : 1.0\n[2018] Deceptio n detectio n using artificial neural network and support\nvector machine [39]\nSVM / Accuracy: 1.0\n[2020] Automa ted Deception Detection of Males and Females from Non-\nVerbal Facial Micro-Gestu res [40]\nRandom Forest / Accuracy : 0.998\n[2019] Face-Foc used Cross-S tream Netwo rk for Deceptio n Detect ion in\nVideos [41]\nNeural Network / Area Under the\nCurve: 0.9978\n[2018] A Multi-Vie w Learnin g Approach To Deception Detection [42] Multi-view Learning / Accuracy :\n0.98\n[2015] A compar ison of features for autom atic deception detection in\nsynchron ous computer -mediated commun ication [43]\nDecision Tree / Accuracy : 0.98\n[2019] Robust Algorit hm for Multimodal Deceptio n Detect ion [44] Combined methods / Accuracy : 0.97\n[2018] Lie Detector with The Analysis Of The Change Of Diameter Pupil\nand The Eye Movement Use Method Gabor Wavelet Transform and\nDecision Tree [45]\nDecision Tree / Precision: 0.97\n[2021] LieNet: A Deep Convo lution Neural Networks Framew ork for\nDetecting Deception [46]\nNeural Network / Accuracy :\n0.967375\n[2017] Deep Learnin g Driven Multimoda l Fusion for Automa ted\nDeceptio n Detection [47]\nNeural Network / Accuracy : 0.964\n[2019] How smart your smartphon e is in lie detection? [48] KNN / Precision: 0.95\n[2012] The Voice and Eye Gaze Behavio r of an Imposter: Automated\nInterviewi ng and Detect ion for Rapid Screening at the Border [49]\nDecision Tree / Accuracy : 0.9447\n[2020] Building a Better Lie Detector with BERT: The Difference Between\nTruth and Lies [50]\nNeural Network / Accuracy : 0.936\n[2021] Deceptio n detectio n in text and its relation to the cultural\ndimensio n of individual ism/colle ctivism [51]\nLogistic Regression / Recall: 0.93\n[2018] Deceptio n detectio n in videos [52] Logistic Regression / Area Under the\nCurve: 0.9221\n[2021] Develo pment of Spectral Speech Features for Deception Detection\nUsing Neural Networks [53]\nNeural Network / Accuracy : 0.9167\n[2012] Syntactic Stylometr y for Deceptio n Detect ion [54] SVM / Accuracy: 0.912\n[2020] Introducin g Represent ations of Facial Affect in Automa ted\nMultimoda l Deception Detection [55]\nAdaBoost / Area Under the Curve:\n0.91\n[2014] Cues to Deceptio n in Social Media Communica tions [56] Gradient Boosting / Accuracy : 0.91\n[2020] Your eyes never lie: A robot magician can tell if you are lying [57] Random Forest / Area Under the\nCurve: 0.897\n[2017] Detecting Deceptive Behavior via Integra tion of Discriminat ive\nFeatures from Multiple Modalities [58]\nDecision Tree / Accuracy : 0.8926\n[2021] Affect-A ware Deep Belief Network Representations for Multimodal\nUnsuperv ised Deception Detection [59]\nNeural Network / Precision: 0.88\n[2020] Emotion Transformat ion Feature: Novel Feature For Deception\nDetection In Videos [60]\nSVM / Accuracy: 0.8759\n[2014] Thermal Facial Analysis for Deception Detection [61] KNN / Accuracy : 0.8688\n[2016] ReLiDS S: Novel lie detection system from speech signal [62] SVM / Accuracy: 0.86375\n[2021] Automat ic Detection of Deceptive and Truthful Paralinguistic\nInformati on in Speech using Two-Lev el Machine Learning Model [63]\nCombined methods / F1-score: 0.856\n[2018] Toward End-to-E nd Deception Detection in Videos [64] KNN / Accuracy : 0.8416\n[2018] Interpret able Multimod al Deception Detection in Videos [65] Neural Network / Accuracy : 0.8416\n[2021] Deceptio n in the eyes of deceiver: A computer vision and machine\nlearning based automate d decepti on detection [66]\nSVM / Precision: 0.84\n[2018] Detection of Deception Using Facial Expressions Based on Differen t\nClassificat ion Algorithms [67]\nNeural Network / Accuracy : 0.84\n(Continued )\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 12 / 31\n\nTable 2. (Continu ed )\nTitle Technique\n[2015] Distingui shing Deception from Non-Dec eption in Chinese Speech\n[68]\nDecision Tree / Recall: 0.83555\n[2013] Deceptio n detectio n in speech using bark band and perceptually\nsignifican t energy features [69]\nNeural Network / Accuracy : 0.8333\n[2019] Speech Deception Detection Algorithm Based on SVM and Acoustic\nFeatures [70]\nSVM / Accuracy: 0.8247\n[2015] Perinasal indicators of deceptive behavior [71] Neural Network / Accuracy : 0.8\n[2018] An Empirical Study on Detecting Deception and Cybercrime Using\nArtificial Neural Networks [72]\nNeural Network / Area Under the\nCurve: 0.7999\n[2018] Compar ative Analys is of Classifica tion Methods for Automatic\nDeception Detection in Speech [73]\nDecision Tree / Unweight ed Average\nRecall: 0.795\n[2016] The Truth and Nothing but the Truth: Multimod al Analysis for\nDeception Detection [74]\nSVM / Accuracy: 0.7895\n[2018] Acoustic-P rosodic Indicato rs of Deception and Trust in Interview\nDialogues [75]\nRandom Forest / Precision: 0.7837\n[2018] Automat ed verbal credibil ity assessme nt of intentions: The model\nstatement technique and predictive modeling [76]\nSVM / Accuracy: 0.7742\n[2019] Automat ic Deception Detection in RGB Videos Using Facial Action\nUnits [77]\nSVM / Accuracy: 0.7684\n[2021] How humans impair automate d decepti on detection performance\n[78]\nRandom Forest / Recall: 0.76\n[2011] Move, and I Will Tell You Who You Are: Detecting Deceptiv e Roles\nin Low-Qual ity Data [79]\nSVM / F1-score: 0.76\n[2021] Unsuper vised Audio-Visua l Subspace Alignment for High-Stakes\nDeception Detection [80]\nKNN / Area Under the Curve: 0.75\n[2018] Convolut ional Bidirectio nal Long Short-Term Memory for Deception\nDetection with Acoustic Features [81]\nNeural Network / Accuracy : 0.7487\n[2019] Joint Learning of Convers ational Temporal Dynamics and Acoustic\nFeatures for Speech Deception Detection in Dialog Games [82]\nNeural Network / Unweight ed\nAverage Recall: 0.7471\n[2018] Intellig ent Deception Detection through Machine Based Interviewin g\n[83]\nNeural Network / Accuracy : 0.74605\n[2019] Can a Robot Catch You Lying? A Machine Learning System to Detect\nLies During Interac tions [84]\nRandom Forest / Area Under the\nCurve: 0.74\n[2013] Automat ic Detection of Deceit in Verbal Commun ication [85] SVM / Accuracy: 0.737\n[2015] Deceptio n Detection Using Real-Life Trial Data [86] Random Forest / Accuracy : 0.7355\n[2021] Detecting Lies is a Child (Robot)\u2019s Play: Gaze-Based Lie Detection in\nHRI [87]\nRandom Forest / Area Under the\nCurve: 0.733\n[2016] Deceptiv e Speech Detection based on sparse representation [88] SVM / Accuracy: 0.7295\n[2020] Multimod al Deception Detection using Real-Life Trial Data [89] Neural Network / Accuracy : 0.7288\n[2021] Identit y Unbiased Deception Detection by 2D-to-3D Face\nReconstruct ion [90]\nNeural Network / Recall: 0.72\n[2012] On the Use of Homogeno us Sets of Subjects in Deceptive Language\nAnalysis [91]\nSVM / Precision: 0.7185\n[2018] Linguisti c cues to deception and perceived deception in interview\ndialogues [92]\nRandom Forest / Precision: 0.71685\n[2019] Automat ic Long-Ter m Deception Detection in Group Interaction\nVideos [93]\nCombined methods / Area Under\nthe Curve: 0.705\n[2015] Detection of Deception in the Mafia Party Game [94] Logistic Regression / Accuracy :\n0.7026\n[2013] Seeing through Deception : A Computationa l Approach to Deceit\nDetection in Written Commu nication [95]\nSVM / F1-score: 0.702\n[2014] Deceptio n Detection Using a Multimodal Approach [96] Decision Tree / Accuracy : 0.701\n[2021] Multimod al Political Deception Detection [97] Decision Tree / Accuracy : 0.7\n(Continued )\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 13 / 31\n\nhelp further studies to direct their effort to fill in the still existing gaps. We report what we\nhave found and discuss it in comparison to deception detection theories, primarily to highlight\nresearch opportunities.\nMany other conclusions were not included as we considered they do not contribute to\nanswering the research questions. Those conclusions, however, can be found in the Jupyter\nLab Notebooks. The following sections present and discuss those themes.\nLanguage and cultural coverage\nWe consider this theme important because it divides the studies into two distinct groups: one\nbased on English and another based on other languages. Verbal cues depend heavily on\nTable 2. (Continu ed )\nTitle Technique\n[2021] Non-inv asive Deception Detection in Videos Using Machine\nLearning Techniques [98]\nSVM / Recall: 0.6972\n[2015] Experim ents in open domain deception detection [99] SVM / Accuracy: 0.695\n[2017] Deceptio n detectio n in Russian texts [100] Clustering / Accuracy : 0.683\n[2019] High-Lev el Features for Multimoda l Deception Detection in Videos\n[101]\nBSSD / Area Under the Curve: 0.671\n[2015] Is Interacti onal Dissynch rony a Clue to Deceptio n? Insights From\nAutomat ed Analys is of Nonver bal Visual Cues [Burgoon, J. K.; Yu, X.;\nZhang, S.; Yan, Z.; Yang, F.; Huang, J.; Dunbar, N. E.; Jensen, M. L.; Metaxas,\nD. N.]\nSVM / Precision: 0.668\n[2018] Deceptio n Detection and Analysis in Spoken Dialogues based on\nFastText [102]\nNeural Network / Precision: 0.667\n[2017] Gender-B ased Multimoda l Deception Detection [103] Decision Tree / Accuracy : 0.664\n[2019] Bag-of-Lie s: A Multimoda l Dataset for Deception Detection [104] Combined methods / Accuracy :\n0.6617\n[2015] Cross-Cul tural Production and Detection of Deception from Speech\n[105]\nRandom Forest / Accuracy : 0.6589\n[2019] Detecting Concealed Information in Text and Speech [106] Neural Network / F1-score: 0.65615\n[2012] Discernin g truth from deception : Human judgme nts and automati on\nefforts [107]\nDecision Tree / Accuracy : 0.65\n[2011] Challenges in automa ted deception detection in computer-me diated\ncommunica tion [108]\nSMO / Accuracy : 0.65\n[2016] Automat ed detection of user deceptio n in on-line question naires with\nfocus on eye tracking use [109]\nSVM / Precision: 0.64\n[2017] Hybrid Acoustic-Lexic al Deep Learning Approach for Deception\nDetection [110]\nNeural Network / F1-score: 0.639\n[2019] Impro ved semi-super vised autoencode r for decepti on detection [111] Neural Network / Accuracy : 0.6278\n[2021] Deceptio n Detection and Remote Physiolo gical Monito ring: A\nDataset and Baseline Experimental Results [112]\nSVM / Accuracy: 0.626\n[2016] Analyzin g Thermal and Visual Clues of Deception for a Non-Contact\nDeception Detection Approach [113]\nDecision Tree / Accuracy : 0.6174\n[2017] Construc tion and Analysis of Indonesian-I nterviews Deception\nCorpus [114]\nRandom Forest / F1-score: 0.613\n[2020] Multiling ual Deception Detection by Autonomou s Agents [115] Neural Network / Accuracy : 0.6\n[2018] Construc tion of a Liar Corpus and Detection of Lying Situatio ns\n[116]\nSVM / Accuracy: 0.5516\n[2019] Detecting Deception in Political Debates Using Acoustic and Textual\nFeatures [117]\nNeural Network / Accuracy : 0.5104\nSource: The authors (2022)\nhttps://d oi.org/10.1371/j ournal.pon e.0281323.t00 2\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 14 / 31\n\nlanguage aspects. Thus, most of the knowledge found in English-based studies needs to be\nadapted or tested for other languages. Statistical details can be found in section 2 (Language\nanalysis) in S6 File (Statistical Analysis Notebook).\nThe statistical analysis results make evident the lack of research regarding deception detec-\ntion in non-English languages. The research on the topic was found only in nine other lan-\nguages (Chinese, Dutch, Hebrew, Indonesian, Italian, Mandarin, Romanian, Russian, and\nSpanish), yet the volume is small (14 papers, 25%) when compared to studies dedicated to\nEnglish (42 papers, 75%). We kept Chinese and Mandarin apart because they were referred to\nas such. Furthermore, most studies on the aforementioned languages are devoted to vocal cues\n[38, 63, 68, 70, 75, 80\u201382, 88, 97, 105, 111, 114, 115].\nWhile facial expressions are universal, gestures are culture-specific [2]. Some visual cues\nrelated to gestures lack more experimentation for different cultures. As an example, the same\ngesture that means \u201cOk\u201d for the American (connecting the thumb to the tip of the pointing fin-\nger) may represent an obscenity for the Brazilian. The messages and emotions related to that\nsame gesture are pretty different. However, no study has taken advantage of this information.\nFrom the 14 studies on non-English [46, 51, 68, 70, 75, 81, 82, 88, 91, 95, 100, 101, 105, 111,\n114, 115], only one consumes visual features [101], and none include gestures such as self-\nadaptors (touching one\u2019s own body, face, or hair) [4], manipulators (pinching, picking,\nscratching) [2], emblems (gestures that replace words) [2], or illustrators (gestures that accom-\npany speech) [2, 4].\nRegarding linguistic cues, one article presents a comprehensive study comparing five lan-\nguages from different parts of the world [51]. Structural differences demonstrate the need for\nspecific approaches for each language or, at least, a group of similar languages.\nTherefore, there is still a large study gap for languages other than English, mainly focusing\ndifferent modalities, features, tools, and techniques. The same can be said about gestures for\nnon-American cultures.\nEmotional features\nEmotional features are important because, according to some authors [2, 4], the act of deceiv-\ning triggers emotional states that induce the behavioral alterations that work as deception cues.\nStatistical details can be found in section 2 (Language analysis) in S6 File (Statistical Analysis\nNotebook).\nDeception is said to be related to three different emotions: guilt, fear, and delight [2]. A\ndeceiver may feel guilty because his/her conscience tells him/her that deceiving is morally\nwrong. Fear comes when a deceiver is afraid of being caught and having to account for his/her\ndeception, eventually feeling ashamed or humiliated when exposed. However, a deceiver can\nfeel delighted when the act of deceiving leads to the joy of fooling others [4].\nSuch emotions can cause several behavioral and physiological changes. Guilt may lead a\ndeceiver to avoid eye contact. Fear may generate physiological arousal and result in eye blink-\ning and the use of self-adaptors. It may also cause speech interferences (pauses, errors, repeti-\ntions, and hesitations) and influence the voice pitch. Negative emotions such as guilt and fear\nmay also decrease the use of illustrators, whereas delight may cause smiling and increase the\nmovements [4]. Despite emotions and deceiving being interrelated, not many studies exploited\nsentiments as a detection approach. Most studies use the behavioral alterations caused by the\nemotional fluctuations instead of emotions.\nThe selected papers explore several different modalities and features, but only two are\ndirectly related to emotions. One is a paper from 2020 that delves specifically into emotion\ntransformation [60] combined with visual features (a bimodal approach, see section 3.4 in S6\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 15 / 31\n\nFile). An SVM classifier trained from visual cues (eye gazing, facial expressions, and hand\nmotions) reached 0.8759 accuracy. Emotions are inferred from visual features. Visual cues\nwere evaluated in space and time to detect both emotion transitions and deception.\nThe other study presents a monomodal approach (see section 3.3 in S6 File) based on emo-\ntional cues [48]. It exploits a mobile app that can monitor the emotion level by noticing the\nuser\u2019s shaking hands. This study reported 0.84 accuracy from a Random Forest classifier but\ndid not measure the specific emotions related to deception.\nTwo other studies exploited sentiment extracted from textual cues [56] and visual cues [74],\nbut report no particular findings regarding the influence of such feature on deception\ndetection.\nStatistical analysis suggests that scrutiny of the emotional effects experienced during decep-\ntion is still a fertile ground for research.\nPsychological traits\nPsychological traits are important because some specific, not-so-usual ones can influence how\na deceiver behaves while telling lies. The expected behavioral shifts may not happen in individ-\nuals that show these traits. However, most studies do not delve deeply into this feature. Statisti-\ncal details can be found in section 4.7 (Remaining features analysis) in S6 File (Statistical\nAnalysis Notebook).\nCertain people represent an exception to the emotional effects when they are deceiving.\nMachiavellian people usually look their accuser right in the eye when they are falsely denying\nsomething, which contradicts the notion of eye aversion [4, 15]. Thus, the deceiver\u2019s psycho-\nlogical profile may influence their behavior and, consequently, over the cues they give away.\nThree studies experimented on psychological features. One consumed NEO-FFI (Neuroti-\ncism-Extraversion-Opennes s Five-Factor Inventory) scores along with demographic and vocal\ncues [105]. NEO-FFI is a five-factor personality model based on an empirically developed tax-\nonomy of personality traits. This model measures five personality components: Openness to\nexperience, Conscientiousness, Extraversion, Agreeableness, and Neuroticism.\nCertain studies confirm that some of the five NEO-FFI dimensions are related to Machia-\nvellian individuals [118, 119] but the papers in question do not report this relationship as the\nreason for including such features in the experiments.\nOne paper reports correlations between Extraversion and Conscientiousness, and the abil-\nity to deceive, but does not relate it to Machiavellianism. Still, we consider NEO-FFI as a prom-\nising set of features for deception detection.\nThe second study combines the NEO-FFI score with demographic and textual features [92]\nthat worked as features for training Random Forest, Logistic Regression, and SVM classifiers.\nThe paper presents some discussion and conclusions on the textual features, but nothing\nabout the psychological ones.\nThe latest study also includes NEO-FFI scores, added by traits such as NARS (Negative\nAttitude towards Robot Scale), Histrionic, and Narcissistic Machiavellianism, as well as visual\nfeatures [84]. Although Machiavellianism was included in the study, it concludes that one\u2019s\npsychological profile does not improve detection performance. It seems that psychological\nprofiling is still both an opportunity for research and a point of doubt, as theoretical and exper-\nimental conclusions from Machine Learning do not align.\nCognitive load\nCognitive load is important because it can disclose the unusual mental effort experienced by a\ndeceiver when telling some elaborate lie, which can be exploited as a deception cue.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 16 / 31\n\nBesides emotional consequences, deceiving may lead to higher cognitive effort since fabri-\ncating an argument is usually more difficult than telling a recollection [1, 4]. Therefore, the\ncognitive load caused by lying, especially when the stakes are high, may produce behavioral\nshifts such as speaking slowly or taking too long to respond [120], as well as blinking less and\nhesitating during speech [4]. Higher cognitive demand also leads to body neglect, resulting in\nfewer body movements. In such scenarios there may be more gaze aversion, as looking at\nother people\u2019s eyes can be distracting [16]. This extra mind work stems from the different\nareas of the brain related to remembering and fabricating a story.\nOut of the 81 selected studies, 8 exploit cognitive load as a predictor in many different\nforms, such as pupil dilation [45, 49, 57, 84], eye blinks [84, 113], body motion [79, 86], time to\nrespond [84], and hesitation [82]. Pupil dilation was reported to have high discriminant power\nfor deception detection. Other features were not said to have any similar contribution.\nNevertheless, exceptions exist. Some people find telling a lie not such a demanding task,\nperhaps because they do it frequently and successfully [4]. This happens with people who are\nverbally skilled, or natural liars. No study among those selected has attempted to measure ver-\nbal skills and establish a relationship with deception detection, although there are papers that\nhave explored syntax complexity [43, 54, 56, 58, 72, 92, 99, 101, 103, 106].\nVocal studies based on cognitive load use no more than silence gaps as predictor. Visual stud-\nies rely on special glasses to acquire images from the eyes to measure displacements of pupils.\nMany verbal features are based on LIWC (Linguistic Inquiry Word Count), a text analyzer\nthat provides psycholinguistic categories for words [121]. While those categories worked as\nfeatures, no attempt to measure the subjects\u2019 verbal skills was found in the selected corpus,\nmaking this another opportunity for study.\nNaturality\nNaturality is important because those who are lying are not in a natural moment (at least for\nmost people). Learning how this factor is addressed by research helps to understand its contri-\nbution to the field.\nOne consequence of deceiving is the deceiver\u2019s attempt to control his or her own behavior.\nLiars may be aware of their interlocutors\u2019 intention to detect deception and try to pose what\nthey consider a natural truth-telling behavior [4]. This may lead to an artificial and rehearsed-\nlike behavior, with unusual body rigidity. Moreover, their speech may also sound extremely\nfluent, with no hesitations or imprecisions, lacking spontaneity [15].\nOne study includes hesitation as a feature [82], while another explores speaking rate [105].\nNeither of them, however, discusses the contribution of those features. No experimental results\nvalidate theoretical expectations so far.\nSource of data\nThe source of data is essential because Machine Learning is highly dependent on the quality\nand quantity of input data. To reduce bias, the data samples used as input for Machine Learn-\ning algorithms must represent the population as closely as possible. Statistical details can be\nfound in section 7.2 (Dataset origin analysis) in S6 File (Statistical Analysis Notebook).\nDeception cues are most noticeable when the deceiver is highly motivated to convince the\nvictim [1, 15, 120, 122]. These are circumstances in which the deceiver foresees undesirable\nconsequences.\nMost studies based on mock data use positive motivations to stimulate deceptions (for\ninstance, awarding a 20 dollars prize to the best deceiver). In contrast, studies that consume\nreal-life data may use a negative motivation (facing punishments dictated by law). It has been\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 17 / 31\n\ndemonstrated that the intensity of motivation is related to physiological changes during decep-\ntion [120, 122].\nThe emotional component of deception detection makes the availability of real-life data\nlabeled with ground truth even more critical. The prevalence of mock data (70.15%) over real-\nlife data (29.85%) challenges some of the results since the influence of mock data over the\nresults is unknown. Even so, such results should not be considered invalid. After all, the\nauthors themselves comment that the lack of real-life data should be considered a research lim-\nitation. However, laboratory conditions offer control over variables, which can be leveraged in\nfavor of research [4].\nThanks to the public release of the \u201cReal-life Trial Deception Detection Dataset\u201d in 2015\n[86], the volume of research with real-life data increased, delivering reports of high-perfor-\nmance results. It is a multimodal dataset, although vocal and textual research are limited to\nEnglish. Studies exploiting vocal and textual cues from other languages lack a version of the\nReal-life Trial dataset.\nFacial cues\nFacial cues are important because the face is the primary vehicle to express someone\u2019s emo-\ntional state. Also, they have been the focus of many studies, for current technology provides\nmany tools for extracting facial features. Statistical details can be found in section 4.2 (Visual\nfeatures analysis) of S6 File (Statistical Analysis Notebook).\nEkman reports that faking an emotion may be easier (especially for professional actors), but\nnot demonstrating strong ones is almost impossible since some facial expressions involuntarily\narise [2]. It is said that these emotions \u201cleak out\u201d, betraying the deceiver.\nFacial expressions, micro-expressions, micro-gestures, and affect were analyzed as features\nin 32 (39.5%) out of the 81 selected papers, with a myriad of performance levels. The highest\none reports 0.97 as accuracy [41, 44]. In general, Bimodal and Multimodal approaches show\nbetter results than Monomodal ones, a synergy between visual and non-visual cues. These\nfindings demonstrate the importance of visual cues for deception detection.\nEye-related features (gaze, blinks and eye saccades) were exploited in 21 studies (22.78%).\nSuch features were chosen because some studies [2] suggest that the gaze suffers the influence\nof some emotions, such as sadness or guilt. Since deception is associated with negative emo-\ntions and arousal of affect [3], those features seem promising. Likewise, eye blinks are usually\nincreased with the arousal of emotions [4].\nHead-related features (head pose and head motion) were exploited in 13 articles (17.58%).\nThose were chosen because some authors relate the head with deception cues [4]. Head shakes,\nnods, and head orientation may express emotional states while the lack of movement may\nindicate a state of self-conscience (self-monitoring) [3].\nThe face is a dual channel of Information. While there are involuntary actions that may\nwork as clues for detection, the face is one of the body parts most monitored by the deceiver\nwhen concealing emotions and mislead the interlocutor [2]. Many studies have measured the\nimportance of such features on detection performance, but none have been able to explain\nhow they influence detection. This is because most of the exploited classifiers are black boxes\n(SVM and Neural Networks).\nTwo works [64, 65] proposed a method to interpret visual features. They used an LSTM\n(Long-Short Term Memory) Neural Network to extract features and a metric named Visual\nAttention to discriminate those face parts that contributed most to a certain classification.\nHowever, other techniques to explain how the results were inferred from the data (named a\npost-hoc explanation) were not exploited [123].\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 18 / 31\n\nTwo others used Decision Tree [113] and Random Forest [86] classifiers. The former sur-\nprisingly reports that facial expressions are not discriminant for deception and truth but could\nnot explain why. Such a conclusion seems to contradict theoretical principles. In contrast, the\nlatter reports facial cues as the most contributing set of features for discerning deception from\nthe truth but provides no measure for the contribution of visual features. The first study con-\nsumed mock data, and the second real-life data. Consequently, while some results suggest the\nrelevance of facial features, neither study made clear which features are more important and\nwhich could be discarded from the feature set, even though Decision Tree methods produce a\nhuman-interpretable output.\nGiven the already mentioned universality of facial expressions, researchers from non-English\nspeaking cultures can take advantage of all these studies as a starting point for their endeavors. As\na final comment relative to facial cues and their importance for deception detection, no experi-\nments in the selected corpus tried to put their findings to the test by submitting them to actors.\nComplexity and performance\nComplexity and performance are important because the processing power computers offer now-\nadays allows researchers to invest in more sophisticated and processor-demanding approaches.\nSome methods that run on a personal computer today were out of possibility 20 years ago.\nData gathered from the reviewed documents allows us to safely claim that there has been an\nincreasing interest on deception detection with Machine Learning in the chosen period. In\naddition, statistical analysis discloses that the approach complexity also increased (see section\n3.2 in S6 File) since different modalities were combined and explored to achieve higher perfor-\nmance levels in different scenarios and under various constraints.\nStatistical analysis shows that Monomodal approaches achieved high-performance levels,\nespecially considering that Monomodal studies constitute the majority of research on the topic\n(33 out of 81 studies, 40.74%). However, a deeper look into such data reveals the presence of\noutliers (see section 8 in S6 File).\nThis comes as a surprise since there is a particular group of lie-catchers that show consis-\ntently high performance for many kinds of deception in many different situations. These\nhuman deception detectors reported using verbal and non-verbal cues, particularly emphasiz-\ning the latter [5]. This suggests that Bimodal and Multimodal approaches should always per-\nform better, but some reported results contradict these expectations. This raises questions\nabout what bias could be interfering on such experiments.\nAnother discrepancy between what the high accuracy detectors said and what the results\nshow is that non-verbal cues are their preference. The detection accuracy levels reported by\nMonomodal visual studies are not the best, except for some outliers. Monomodal vocal studies\npresent higher accuracy than visual ones. Thus, under a different form, the results still seem to\ndefy the theoretical framework. Reasons for that are yet to be understood.\nStatistical analysis reveals that all those textual Monomodal approaches trained their classifi-\ners with data extracted from non-real-life situations and online deception game sessions. Only\na few visual and vocal Monomodal studies built their classifiers from real-life data [60, 73, 77].\nCould the features extracted from real-life and mock settings be different enough to justify\nsuch surprising outcomes? No conclusion can be drawn at this moment, but this doubt raises\nessential questions that should be answered by future research.\nMachine Learning algorithms\nMachine Learning algorithms are important because the area offers a wide range of possibili-\nties for classification problems, not counting clustering and association rules, among others.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 19 / 31\n\nStatistical details can be found in section 5 (Machine Learning analysis) in the S6 File (Statisti-\ncal Analysis Notebook).\nAuthors exploited the Machine Learning arsenal by experimenting with 26 different algo-\nrithms. The top five (see section 5.1 in S6 File) is composed by Neural Networks (34 times,\n30.09%), Support Vector Machines (SVM) (28 times, 24.78%), Random Forest (20 times,\n17.70%), Decision Tree (21 times, 18.58%), and K-Nearest Neighbor (KNN) (10 times, 8.85%).\nSuch algorithms are prevalent and a preference for them is not surprising. AdaBoost (6 papers,\n14.63%), Na\u00efve Bayes (6 papers, 14.63%), Logistic Regression (6 papers, 14.63%), and Sequen-\ntial Minimal Optimization (SMO) (3 papers, 7.32%) come next as the second group of prefer-\nence. Each of the other 16 (39.09%) algorithms had been exploited once (see section 5 in S6\nFile).\nFour of the top five most exploited Machine Learning techniques present variations (see\nsection 5.2 in S6 File). The variation choice gives an idea of how the authors understand the\nproblem, how complex they expected it to be, and what are their hypotheses regarding the\ndata.\nSupervised learning was used in 80 studies since these modeled the deception detection\nproblem as a binary classification task. However, one study [59] addressed the scarcity of\nlabeled ground truth data by proposing an unsupervised model. Such work used a Deep Belief\nNetwork (DBN) trained from monomodal e multimodal features to elaborate a clustering sys-\ntem based on a metric they named \u201cfacial affect\u201d.\nThe following sections discuss the most recurring Machine Learning models in the corpus.\nArtificial Neural Networks and deep learning. Neural Networks were used 34 times\n(28.44%) in 81 papers. This technique was exploited in 10 different variations. Multi-layer Per-\nceptron (MLP) appeared in 12 papers (35.29%), Long Short-Term Memory (LSTM) networks\nin 9 papers (26.47%), and Convolutional and Levenberg-Marquardt (MLN) networks in 3\npapers (8.82%) each. Another 7 flavors had a single use, and include Autoencoder, BERT,\nDeep Belief Network, Deep Learning, Multi-input, Recurrent-Convoluti onal, and Virtual Gen-\neralizing RAM.\nThe MLP model is the older multilayer feed-forward model for Neural Networks. Its popu-\nlarity come from the late 1980s when the backpropagation training algorithm was introduced\n[33]. It can model non-linear relationships in data, which seems to be the case for deception\ndetection. One of its virtues is to be trained quickly in nowadays GPU-based computers\n(mostly, training lasts up to 5 minutes).\nThe performances of MLP models were measured by accuracy in 11 [39, 40, 43, 56, 66, 67,\n71, 72, 83, 89, 102] out of the 12 studies. Those accuracy rates range from 0.6333 to 0.9665,\nwith a mean at 0.7961 \u00b1 0.1130. The other study [68] evaluated performance by F1-score,\nwhich measured 0.7633.\nLevenberg-Marquardt Networks are a kind of MLP that uses a variation of the backpropa-\ngation algorithm aiming to accelerate its convergence. It is also a non-Deep Learning method.\nThe three studies [38, 53, 69] that exploited this kind of Neural Network presented accuracies\nranging from 0.7916 to 0.8750, with a mean at 0.8333 \u00b1 0.0417.\nOn the other hand, LSTMs are Deep Learning recurrent networks that achieve excellent\nresults against problems like time series and Natural Language Processing. This kind of net-\nwork can model non-synchronic relationships in data. That was the reason for its choice in\nmany studies. Authors hypothesize that the deception cues happen close to each other, but not\nnecessarily simultaneously.\nLSTM model performances were measured by accuracy in 5 [38, 50, 53, 65, 81] out the 9\nstudies. Those accuracies range from 0.7487 to 1.0, with a mean at 0.8886 \u00b1 0.0965. In two\ncases [106, 110] the measure was F1-score, as 0.6390 and 0.6562. In one study [101] the\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 20 / 31\n\nperformance was reported as Area Under the Curve, which measured 0.6650, and in the other\n[82] the Unweighted Average Recall measured 0.7471.\nAnother Deep Learning flavor is the Convolutional Neural Network (CNN), which has\nshown particular success for computer vision. In this model, high-dimensional data is com-\npressed into fewer discriminating features, then processed by hidden layers in a manner simi-\nlar to MLP.\nThe CNN model was measured by accuracy in all three studies [46, 47, 90]. These range\nfrom 0.6800 to 0.9674 with a mean at 0.8705 \u00b1 0.1650.\nOnly MLP and MLN are not Deep Learning models, and together they appear in 15 articles\n(44.11%). All other flavors of Neural Networks (19 papers, 55.89%) use Deep Learning in sev-\neral variations, revealing a trend of choice. We consider the trend natural given the level of\nexcellence Deep Learning models have shown in the last decade. One of their virtues is that\nfeature selection is automatic.\nHowever, Deep Learning methods rely on large amounts of data to produce results free or\nwith low bias. They also rely heavily on GPU power to be trained, and their architectures can\nbecome highly complex. This can be a problem for deception detection since labeled data in\nunconstrained circumstances is scarce. Then, some authors opted to exploit Autoencoders [80,\n111], Deep Learning models that do not consume labeled data. Those are very recent works\nthat may show a promising answer to the data scarcity problem.\nThe two studies that exploited Autoencoder present accuracies of 0.6278 and 0.6950. For\nmore details, see section 5.3.1 in S6 File.\nSupport Vector Machines. Support Vector Machines (SVM) was the second most preva-\nlent technique across all studies (28 times, 25.69%), and was mostly used with what is called a\nLinear kernel (23 times, 82.14%). The other choice was a Radial Basis Function (RBF) kernel\n(5 times, 17.86%).\nSVM divides the feature space into optimum hyperplanes and uses them to make decisions\n[18]. The Linear kernel flavor is used when the data is believed to have linear relationships.\nNonlinear kernels are used when a linear solution is not possible. When working with RBF\nkernels (also called Gaussian kernels), the feature space is distorted to a higher-dimensional\nspace where a hyperplane can be used to separate it [124].\nAmong the studies that use Linear SVM, 18 [39, 43, 44, 54, 56, 60, 62, 66, 67, 72, 74, 76, 85,\n88, 91, 98, 99, 116] measured their performance by accuracy, ranging from 0.5516 to 1.0, with\nmean at 0.7752 \u00b1 0.1121. Three studies [68, 79, 95] measured their performance by F1-score,\nwhich a range from 0.6012 to 0.7800 and mean at 0.7061 \u00b1 0.0709. One study [52] reported the\nArea Under the Curve as 0.9034, and another [125] precision as 0.6680 and recall as 0.6590.\nThe five studies that used RBF SVM [70, 77, 89, 109, 112] measured their performances by\naccuracy, which ranges from 0.5650 to 0.8247, with mean at 0.6808 \u00b1 0.1101. For more details,\nsee section 5.3.2 in S6 File.\nRandom Forest. This technique is an example of an ensemble model. It combines several\nmodels to produce a better one [124]. Random Forest does not have different flavors. The final\nmodel is a composite of several randomly generated decision trees, all combined to make the\nfinal prediction [19]. Its main advantage over decision trees is that the final model usually\noverfits less.\nAmong the 20 studies that exploited Random Forest, 16 [40, 48, 56, 60, 66, 73, 75, 77, 78,\n84, 86, 89, 92, 98, 105, 114] measured their performance by accuracy, which ranges from\n0.5677 to 0.9980, with mean at 0.7301 \u00b1 0.1182. Three other studies [52, 57, 87] measured their\nperformance by Area Under the Curve, which values 0.7330, 0.8131, and 0.8970. One last\npaper [106] reported an F1-score of 0.5963. For more details, see section 5.3.2 in S6 File.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 21 / 31\n\nDecision Trees. Decision Trees models divide the feature space to build a series of parti-\ntions organized hierarchically into conditions [19]. The final model is human-readable, which\nmakes this technique attractive because it helps to understand the relationships existing in data.\nDecision Trees appeared 21 times (18.58%), among which 19 [40, 43, 45, 49, 58, 60, 71, 73,\n86, 96\u201398, 103, 105, 107, 108, 113] in its vanilla flavor (the technique as originally proposed).\nThose measured performance by accuracy, which ranges from 0.5708 to 0.9800, with a mean\nat 0.5708 \u00b1 0.1370. One study [52] measured the performance by Area Under the Curve as\n0.8074, and the other [68] reported an F1-score of 0.8095.\nOne study [48] exploited a variation named Random tree and reported accuracy as 0.8200,\nand another [68] a Gradient-boosted version and reported an F1-score performance of 0.8207.\nFor more details, see section 5.3.4 in S6 File.\nK-Nearest Neighbor. K-Nearest Neighbor (KNN) uses an arbitrary number of k neighbor\npoints to predict the new data class. A voting process is used, so the majority of neighbors will\ndetermine the class of the new data point [124].\nKNN appeared 10 times (8.85%), among which eight [43, 60, 61, 67, 72, 73, 80, 98] in its\nvanilla flavor. Those measured performance by accuracy, which ranges from 0.5723 to 0.8688,\nwith a mean at 0.7527 \u00b1 0.1029.\nOne study [64] exploited a variation named Large Margin Nearest Neighbor and reported\nan accuracy as 0.8416. Another different version was IB1 [48], which reported accuracy as\n0.8100. For more details, see section 5.3.5 in S6 File.\nHeterogeneous approaches. Most multimodal works used the same algorithms for all the\nmodalities, but four studies [44, 63, 93, 104] exploited combining different algorithms for dif-\nferent modalities and demonstrated that such a decision improved their results.\nThose studies hypothesize that different algorithms better process different sets of features.\nThus, they exploited a kind of ensemble classifier, having each algorithm dedicated to a specific\nmodality.\nDataset benchmark\nA dataset benchmark is essential because Machine Learning dramatically depends on both\ndata quality and volume to perform well.\nThe S6 File (Statistical analysis Jupyter Notebook) provides many charts and tables that\ndescribe the datasets in various facets, including a table that lists each paper with details about\nthe dataset it consumes. Those details include cardinality, origin, access, modalities, features,\nand applied algorithms.\nThe \u201cReal-life Trial Deception Detection Dataset\u201d was used in 17 of the 81 studies. It is a\nwell-balanced, 121-row dataset built from videos collected from YouTube. Each video section\nwas labeled as true or deceptive based on police evidence. In four cases, the studies used a sub-\nset of the dataset, and in two others, a superset.\nThe largest real-life dataset has 6,733 instances, the shortest has 6 instances. Among the\nnon-real-life datasets, the largest has 137,640 instances and the shortest has 40 instances.\nCurrent state and further research\nActors specialize in displaying fake emotions, and the face plays an essential role in this con-\ntext. Would they be able to mislead an already trained Machine Learning Deception Detector?\nEkman talks about how to detect false emotions [2], but not one study included that in their\nresearch.\nIt has been suggested that there is no relationship between detection accuracy and demo-\ngraphic aspects (age, gender, or profession) of the human lie-catcher [7], except for secret\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 22 / 31\n\nservice agents, who show a correlation between accuracy, profession, and experience. High-\naccuracy catchers exploit different cues than those with lower performance, suggesting that\nspecific cues carry important information about deception.\nAlthough profession does not seem to be related to lie-catching skills, even high-perfor-\nmance catchers show a particular ability with certain kinds of deception, having a performance\ndecrease when faced with other kinds [5, 15]. The conclusion is that certain kinds of lies pro-\nduce different cues than others, and the experience on detecting a given kind of deception\ndoes not guarantee skills to detect others.\nMoreover, situational and idiosyncratic factors can affect the subjects\u2019 behavior and, there-\nfore, which cues are leaked when deceiving. Such cues are more specific and challenging to\ndetect [4]. Not considering these factors can decrease the detection accuracy\u2014a situation\nreferred to as the Brokaw hazard [2].\nThis finding works as a reasonable explanation for the variety of experiment results. While\nthere are several reliable deception clues, exceptions exist because they may suffer from certain\ninterferences, particularly the so-called Othello error [2]. The Othello error occurs when lie-\ncatchers confuse emotions and motivations. The emotion is present, but it does not originate\nfrom deception.\nThis is a strong stimulus for further research and efforts to produce labeled datasets from\nactual data under more diverse circumstances. More cues could be identified and related to par-\nticular settings. Fake expressions from actors could be an important addition to the datasets.\nSuperior lie-catchers seem to acquire their ability from a personal desire to perform better\non their job, no matter what it is [5]. It is like any other professional skill or talent, improved\nthrough effort, dedication, personal interest, technical knowledge, and training. Thus, such\nhighly skilled lie-catchers result from intense dedication, which is a motivating factor for fur-\nther research on deception detection. It is reasonable to believe that those levels of accuracy\ncan be approximated or even replicated by a Machine Learning classifier given the correct cues\nare processed and interpreted.\nThe diversity of circumstances lie-catchers face improves and generalizes their abilities.\nThis shows the importance of having labeled real-life data collected from diverse sources,\nincluding children and people under medical and psychological treatment, police interroga-\ntions, and witnesses in a trial. This creates another research gap to be filled.\nThe variety of different Machine Learning techniques suggests that the field is still being\nexplored, although there are some high-performance results (Table 1). We believe that the\nvariety of feature kinds exploited suggests that authors are still uncertain about which ones are\nthe most informative. They are gauging the potential of certain cues as deception indicators.\nDifferent modality cardinalities and combinations and the plethora of features are evidence\nthat the topic still offers room for research.\nLimitations and further work\nThis research aims to present a comprehensive overview of the state of knowledge about\ndeception detection with Machine Learning, paying special attention to the performance level\nreported by each study and what data and features they consumed to achieve that perfor-\nmance. However, due to time restrictions and the number of researchers, the period of interest\nwas limited to 2011\u20132021. It is known that some studies were excluded from the corpus, but\nwe consider this acceptable since the last decade shows a great evolution of the field.\nIn addition, other scientific sources such as Google Scholar, Semantic Scholar, and Con-\nnected Papers were not queried for the same reasons above. They could have provided other\npapers to complement the current corpus.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 23 / 31\n\nWe intend to expand our protocol to include those scientific sources, and improve Biblio-\nAlly to handle them. Once new documents are included and analyzed, new versions of the\nmetadata will be made available to provide a more complete panorama of the field.\nConclusions\nThis literature review aims to comprehensively overview of the application of Machine\nLearning to deception detection by reporting on techniques, approaches, data, and perfor-\nmance levels. We searched, retrieved and selected papers, which were summarized as mind\nmaps. We extracted metadata and encoded it as Python dictionaries. All are available for free\naccess.\nA total of 648 bibliographic references were retrieved, with 540 being screened (108 were\nduplicates). We selected only those that have results directly related to deception detection\nwith Machine Learning. Such studies had to present the data features they consumed and the\nperformance level achieved. Only non-invasive approaches were accepted. The final corpus\n(81 documents) reports the results of experiments on deception detection with Machine\nLearning. BiblioAlly was an important asset for conducting the study, helping to manage and\ntrack the steps of the process.\nWe could reach several conclusions from the findings of this review:\na) Authors modeled deception detection as a classification problem (supervised learning),\nexcept for one case that proposed a clustering-based solution (unsupervised learning);\nb) The volume of production on the topic suggests a progressive increase of interest;\nc) The preference for monomodal studies has changed to bimodal and multimodal, over time;\nd) Features exploited are variated and include mostly language and culture, emotion exploita-\ntion, psychological traits, cognitive load, many facial cues, complexity, performance, and\nvarious Machine Learning algorithms;\ne) The absolute majority of works that exploit verbal and vocal features are dedicated to\nEnglish; there is a clear gap for other languages and cultures;\nf) While the theory on deception detection strongly relates it to the subject\u2019s emotional state,\nmost studies did not approach the problem under this perspective, rather modeling the fea-\ntures from behavioral changes;\ng) Machiavellianism is a psychological trait that can change the interpretation of detection\ncues, but authors did not exploited it;\nh) Cognitive load was exploited mostly from the pupil dilation with promising results, but eye\nsaccades, head motions, and syntax complexity also appeared;\ni) Facial cues were exploited in many ways by many works with a variety of feature sets; Open-\nFace was the most used supporting tool for these works;\nj) Vocal cues were almost exclusively provided by OpenSMILE and in general are reported as a\nhighly discriminant feature set;\nk) Naturality was exploited by hesitation and speaking rate, but not much was reported as the\ncontribution of this sort of cue;\nl) Most studies consumed mock data, but after the release of the \u201cReal-life Trial Deception\nDetection Dataset\u201d there is an increase of papers that consume it;\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 24 / 31\n\nm) The scarcity of real-life labeled data with open access still stands as a major challenge for\nthe field;\nn) Neural networks, Support Vector Machines, Logistic Regression, K-Nearest Neighbor and\nDecision Trees were the most exploited Machine Learning algorithms;\nThe variation of size, source, and features of the data consumed is so high that it\u2019s impossi-\nble compare works results. Although a multitude of distinct approaches had been tested with\nseveral performance levels for over a decade, the field still seems to be at initial stages of\ndevelopment.\nIndustry application looks premature at present. Most experiments are based on mock data,\nand even those operating on real-life data are restricted to particular cultures and circumstances.\nWe assess that the risk of bias is high since the datasets used are recurrent and neither large\nnor diverse enough to provide a highly general classifier. There are also no reports on methods\ntested under real-world scenarios. This perception is strengthened by the high risk of bias\nidentified in many of the studies by applying PROBAST.\nAs a result, the overall conclusion is that there is still room for novel approaches, especially\nbased on real-life data from non-English, and from different cultures. Results seem to be\npromising, as some experiments report a very high accuracy level.\nReplicating the performance of human lie-catchers may be considered possible if the topic\nreceives investment. Experiments with more data collected from real, every day, and diverse\nconditions would produce more robust solutions and raise results and techniques to a level of\npotential industrialization and commercialization.\nSupporting information\nS1 File. AMSTAR-2 tool for quality assessment. Source: The authors (2022).\n(PDF)\nS2 File. PROBAST tool for risk of bias assessment. Source: The authors (2022).\n(XLSX)\nS3 File. 1-Definition.pdf Jupyter Lab Notebook. Source: The authors (2022).\n(PDF)\nS4 File. 2-Corpus collection.pdf Jupyter Lab Notebook. Source: The authors (2022).\n(PDF)\nS5 File. 3-Corpus analysis.pdf Jupyter Lab Notebook. Source: The authors (2022).\n(PDF)\nS6 File. 4-Statistical analysis Jupyter Lab Notebook. Source: The authors (2022).\n(PDF)\nS7 File. 5-Mindmaps Jupyter Lab Notebook. Source: The authors (2022).\n(PDF)\nS1 Checklist. PRISMA 2009 checklist. Source: The authors (2022).\n(PDF)\nAcknowledgmen ts\nWe thank the Academic Publishing Advisory Center (Centro de Assessoria de Publicac \u00b8 \u00e3o Aca-\nd\u00eamica, CAPA\u2013 www.capa.ufpr.br) of the Federal University of Parana \u00b4 (UFPR) for assistance\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 25 / 31\n\nwith English language developmental editing. Likewise, we thank the priceless assistance of\nDr. Audrey Tieko Tsunoda, Dr. Emerson Borsato, Mr. Yaniv Pivo, and Mr. Paulo Henrique\nTagliari Silva, for their time on language review and suggestions.\nAuthor Contributions\nConceptualization: Alex Sebasti\u00e3o Consta \u02c6 ncio, Denise Fukumi Tsunoda, Deborah Ribeiro\nCarvalho.\nData curation: Alex Sebasti\u00e3o Consta \u02c6 ncio, Denise Fukumi Tsunoda.\nFormal analysis: Alex Sebasti\u00e3o Consta \u02c6 ncio.\nInvestigation: Alex Sebasti\u00e3o Consta \u02c6 ncio, Denise Fukumi Tsunoda.\nMethodology: Alex Sebasti\u00e3o Consta \u02c6 ncio, Helena de Fa \u00b4 tima Nunes Silva, Jocelaine Martins da\nSilveira, Deborah Ribeiro Carvalho.\nSoftware: Alex Sebasti\u00e3o Consta \u02c6 ncio.\nSupervision: Helena de Fa \u00b4 tima Nunes Silva, Deborah Ribeiro Carvalho.\nWriting \u2013 original draft: Alex Sebasti\u00e3o Consta \u02c6 ncio.\nWriting \u2013 review & editing: Denise Fukumi Tsunoda, Helena de Fa \u00b4 tima Nunes Silva, Joce-\nlaine Martins da Silveira, Deborah Ribeiro Carvalho.\nReferences\n1. Zucke rman M, DePaulo BM, Rosenthal R. Verbal and nonverb al communic ation of deception . In:\nAdvances in Experimental Social Psychology. Academic Press Inc.; 1981.\n2. Ekman P. Telling Lies. New York, NY: W. W. Norton & Comp any, Inc; 1992.\n3. Burgoon JK, Guerrero LK, Floyd K. Nonverbal communic ation. 2nd ed. Nonverbal Commun ication.\nNew York, NY: Routledgr ; 2016. 1\u2013509 p.\n4. Vrij A. Detecting Lies and Deceit: Pitfalls and Opportuniti es. 2nd ed. Chiches ter: John Wiley & Sons,\nLtd; 2008.\n5. O\u2019Sullivan M, Ekman P. The wizards of deception detection. The Detecti on of Deception in Forensic\nContex ts. 2004. p. 269\u201386.\n6. DePaulo , Bella M., Charlton, Kelly., Cooper, Harris., Lindsay, James. J., & Muhlenb ruck L. The accu-\nracy-confid ence correlation in the detection of deception . Vol. 1, Personality and Social Psychology\nReview. Lawrence Erlbaum Associat es, Inc.; 1997. p. 346\u201357 .\n7. Ekman P, O\u2019Sullivan M. Who Can Catch a Liar? Am Psychol. 1991; 46(9):913\u2013 20. https://doi.or g/10.\n1037//00 03-066x. 46.9.913 PMID: 195801 1\n8. Alzubi OA, Alzubi JA, Al-Zoubi AM, Hassonah MA, Kose U. An efficient malwa re detection approac h\nwith feature weighting based on Harris Hawks optimization . Cluste r Comp ut [Internet]. 2022 Aug 8; 25\n(4):2369\u20138 7. Available from: https://link.sp ringer.com/10 .1007/s1058 6-021-0345 9-1\n9. Alzubi JA, Alzubi OA, Beseiso M, Budati AK, Shanka r K. Optimal multiple key-based homomorp hic\nencryption with deep neural networks to secure medical data transmiss ion and diagnosis . Expert Syst\n[Interne t]. 2022 May 11; 39(4). Availab le from: https://onlin elibrary.w iley.com/ doi/10.1111/ex sy.12879\n10. Alzubi OA. Quant um readout and gradient deep learning model for secure and sustainabl e data\naccess in IWSN. PeerJ Comput Sci [Internet]. 2022 Jun 6; 8:e983. Available from: https://peer j.com/\narticles/c s-983 PMID: 35721415\n11. Thakk ar A, Lohiya R. A Review on Machine Learning and Deep Learning Perspective s of IDS for IoT:\nRecen t Updates, Security Issues, and Challeng es. Arch Comput Methods Eng [Internet ]. 2021 Jun 20;\n28(4):3211 \u201343. Available from: https://link.s pringer.com/ 10.1007/s11 831-020-09 496-0\n12. Sousa T, Correia J, Pereira V, Rocha M. Generative Deep Learning for Targeted Comp ound Design. J\nChem Inf Model [Interne t]. 2021 Nov 22; 61(11):534 3\u201361. Available from: https://pubs. acs.org/doi /10.\n1021/acs .jcim.0c01496 PMID: 346997 19\n13. Mohri M, Rostamiza deh A, Talwalk ar A. Foundations of Machine learning. London: The MIT Press;\n2012.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 26 / 31\n\n14. Levine TR. Truth-Defa ult Theory (TDT): A Theory of Human Deception and Decept ion Detection. J\nLang Soc Psychol. 2014; 33(4):378\u2013 92.\n15. DePaulo BM. Spotting Lies: Can Humans Learn to Do Better? Curr Dir Psychol Sci. 1994; 3(3):83\u20137.\n16. Vrij A, Akehurst L, Soukara S, Bull R. Detecting deceit via analyses of verbal and nonverbal behavior\nin childre n and adults. Hum Commun Res. 2004; 30(1):8\u201341 .\n17. Ball TJ. The Polygraph Museum [Internet ]. [cited 2022 Mar 17]. http://w ww.lie2me. net/\nthepolygr aphmuseum /id16.html\n18. Bell J. Machine Learning. Indianapolis: Wiley; 2015.\n19. Alzubi J, Nayyar A, Kumar A. Machine Learning from Theory to Algorithms: An Overview. J Phys Conf\nSer. 2018; 1142(1).\n20. Goodf ellow I, Yoshua B, Courville A. Deep learning. Cambridge , MA, USA: MIT Press; 2016.\n21. Singh A, Thakur N, Sharma A. A review of supervised machine learning algorithms . Proc 10th INDIA-\nCom; 2016 3rd Int Conf Comput Sustain Glob Dev INDIACom 2016. 2016;13 10\u20135.\n22. Kelleher JD, Namee B Mac, D\u2019arcy A. Fundamen ts of Machine Learning for Predictiv e Data Analytics .\n1 Ed. Camb ridge, MA, USA: The MIT Press; 2015. 691 p.\n23. El-Sappa gh S, Ali F, Abuhme d T, Singh J, Alonso JM. Automatic detection of Alzheime r\u2019s disease pro-\ngression: An efficient informati on fusion approac h with heterogene ous ensemble classifiers. Neuro-\ncomput ing [Internet]. 2022; 512:203\u201324. Availab le from: https://doi. org/10.1016/j .neucom.202 2.09.\n009\n24. Sriniva su PN, Sivasai JG, Ijaz MF, Bhoi AK, Kim W, Kang JJ. Classifi cation of Skin Disease Using\nDeep Learning Newural Networks with MobileNet V2 LSTM. Sensors (Switzerl and). 2021; 21:1\u201327 .\n25. Alfian G, Syafrud in M, Ijaz MF, Syaekhoni MA, Fitriyani NL, Rhee J. A persona lized healthcare moni-\ntoring system for diabetic patients by utilizing BLE-based sensors and real-tim e data processing . Sen-\nsors (Switzerl and). 2018; 18(7). https://doi.or g/10.339 0/s18072183 PMID: 29986473\n26. Ali F, El-Sappagh S, Islam SMR, Ali A, Attique M, Imran M, et al. An intelligent healthcare monitori ng\nframew ork using wearabl e sensors and social network ing data. Futur Gener Comput Syst [Internet ].\n2020; 114:23\u201343. Availab le from: https://doi. org/10.1016/j .future.2 020.07.047\n27. Ali F, Ali A, Imran M, Naqvi RA, Siddiqi MH, Kwak KS. Traffic accident detection and condition analysis\nbased on social networking data. Accid Anal Prev [Internet]. 2021; 151(January ):105973. Available\nfrom: https://doi.or g/10.101 6/j.aap.2021 .105973 PMID: 33461071\n28. Quinlan JR. Learning decision tree classifiers. ACM Comp ut Surv. 1996; 28(1):71\u20132 .\n29. Rish I (T. JWRC). An empirical study of the naive Bayes classif ier. In: IJCAI 2001 workshop on empiri-\ncal methods in artificial intelligenc e [Internet]. Seattle , Washingto n, USA; 2001. p. 41\u20136. https://ww w.\nijcai.or g/past/ijcai- 01/\n30. Mammo ne A, Turchi M, Cristianini N. Support vector machines . Wiley Interdi scip Rev Comput Stat.\n2009; 1(3):283\u20139 .\n31. Sinaga KP, Yang MS. Unsupervis ed K-means clustering algorithm . IEEE Access. 2020; 8:80716 \u201327.\n32. Breima n L (University of C). Random Forests. Mach Learn. 2001;(45):5 \u201332.\n33. da Silva IN, Spatti DH, Flauzino RA, Liboni LHB, Alves SF do R. Artificial Neural Networks\u2014 A practical\ncourse. Springer International Publish ing Switzerland, editor. Springer; 2017. 307 p.\n34. Wani MA, Bhat FA, Afzal S, Khan AI. Advances in Deep Learning. Sciences PA of, editor. Vol. 57.\nWarsaw : Springer Interna tional Publishing; 2019. 159 p.\n35. Snyder H. Literat ure review as a research methodol ogy: An overview and guidelines. J Bus Res [Inter-\nnet]. 2019; 104(July) :333\u20139. Available from: https://doi.or g/10.101 6/j.jbusres .2019.07.039\n36. Shea BJ, Reeves BC, Wells G, Thuku M, Hamel C, Moran J, et al. AMSTAR 2: A critical apprais al tool\nfor systematic reviews that include random ised or non-rando mised studies of healthcare interven tions,\nor both. BMJ. 2017; 358:1\u20139. https:// doi.org/10.11 36/bmj.j40 08 PMID: 289357 01\n37. Moons KGM, Wolff RF, Riley RD, Whiting PF, Westwo od M, Collins GS, et al. PROBAST : A tool to\nassess risk of bias and applicability of prediction model studies: Explanation and elaboration . Ann\nIntern Med. 2019; 170(1):W1\u20133 3. https://doi. org/10.7326/M 18-1377 PMID: 30596876\n38. Fernan des S V., Ullah MS. Use of Machine Learning for Deception Detecti on from Spectra l and Ceps-\ntral Feature s of Speech Signals. IEEE Access. 2021; 9:78925\u201335.\n39. Srivastava N, Dubey S. Decept ion detection using artificial neural network and support vector\nmachine. Proc 2nd Int Conf Electron Commun Aerosp Technol ICECA 2018. 2018;(Ice ca):1205\u20138.\n40. Crocke tt K, O\u2019Shea J, Khan W. Automate d Deception Detection of Males and Females from Non-Ver-\nbal Facial Micro-Ges tures. Proc Int Jt Conf Neural Networ ks. 2020;\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 27 / 31\n\n41. Ding M, Zhao A, Lu Z, Xiang T, Wen JR. Face-focus ed cross-stream network for deception detection\nin videos. Proc IEEE Compu t Soc Conf Comput Vis Pattern Recogn it. 2019; 2019-June(2 ):7794\u2013 803.\n42. Cariss imi N, Beyan C, Murino V. A multi-view learning approach to deception detection. Proc\u201413 th\nIEEE Int Conf Autom Face Gesture Recognition , FG 2018. 2018;599\u2013606 .\n43. Pak J, Zhou L. A comparison of features for automatic deception detection in synchronou s computer-\nmediated commu nication. 2015 IEEE Int Conf Intell Secur Informatics Secur World through an Align-\nment Technol Intell Humans Organ ISI 2015. 2015;141\u20133.\n44. Venkatesh S, Rama chandra R, Bours P. Robust Algorithm for Multimo dal Decep tion Detection. Proc\n\u20142nd Int Conf Multimed Inf Process Retrieval, MIPR 2019. 2019;53 4\u20137.\n45. Labiba h Z, Nasrun M, Setian ingsih C. Lie Detector With The Analysis Of The Change Of Diame ter\nPupil and The. 2018;214\u201320.\n46. Karnati M, Seal A, Yazidi A, Krejcar O. LieNet: A Deep Convo lution Neural Networks Framework for\nDetecti ng Deception. IEEE Trans Cogn Dev Syst. 2021; 8920(c) :1\u201315.\n47. Gogat e M, Adeel A, Hussain A. Deep learning driven multimodal fusion for automated deception\ndetection. 2017 IEEE Symp Ser Comput Intell SSCI 2017\u2014Pro c. 2018;2018-Jan ua:1\u20136.\n48. Mizanur Rahman M, Shome A, Chellapp an S, Alim Al Islam ABM. How smart your smartphon e is in lie\ndetection? ACM Int Conf Procee ding Ser. 2019;33 8\u201347.\n49. Elkins AC, Derrick DC, Gariup M. The Voice and Eye Gaze Behavio r of an Imposter: Automate d Inter-\nviewing and Detecti on for Rapid Screen ing at the Border. Conf Eur Chapter Assoc Comput Linguist.\n2012;49 \u201354.\n50. Barsever D, Singh S, Neftci E. Building a Better Lie Detector with BERT: The Difference between\nTruth and Lies. Proc Int Jt Conf Neural Networ ks. 2020;\n51. Papan toniou K, Papadakos P, Patkos T, Flouris G, Androuts opoulos I, Plexousa kis D. Deception\ndetection in text and its relation to the cultural dimension of individualis m/collectivis m. Nat Lang Eng.\n2021;1\u2013 62.\n52. Wu Z, Singh B, Davis LS, Subrahma nian VS. Decept ion detection in videos. 32nd AAAI Conf Artif Intell\nAAAI 2018. 2018;1695\u201370 2.\n53. Fernan des S V., Ullah MS. Developm ent of Spectra l Speech Features for Deception Detection Using\nNeural Networks. 2021 IEEE 12th Annu Inf Technol Electro n Mob Commun Conf IEMCON 2021.\n2021;19 8\u2013203.\n54. Feng S, Banerjee R, Choi Y. Syntactic stylome try for deception detection. 50th Annu Meet Assoc\nComp ut Linguist ACL 2012\u2014Pro c Conf. 2012; 2(July):1 71\u20135.\n55. Mathur L, Matari\u0107 MJ. Introducing Representa tions of Facial Affect in Automate d Multimodal Decep-\ntion Detection. ICMI 2020\u2014 Proc 2020 Int Conf Multimodal Interact. 2020;305\u201314.\n56. Briscoe EJ, Appling DS, Hayes H. Cues to deception in social media communic ations. Proc Annu\nHawaii Int Conf Syst Sci. 2014;1435\u201343 .\n57. Pasqua li D, Aroyo AM, Gonzalez -Billandon J, Rea F, Sandini G, Sciutti A. Your eyes never lie: A robot\nmagician can tell if you are lying. ACM/IE EE Int Conf Human-Robot Interact. 2020;39 2\u20134.\n58. Aboue lenien M, Perez-Ro sas V, Mihalcea R, Burzo M. Detecting Deceptiv e Behavior via Integra tion of\nDiscrimi native Feature s from Multiple Modalitie s. IEEE Trans Inf Forensics Secur. 2017; 12(5):1042 \u2013\n55.\n59. Mathur L, Mataric MJ. Affect-Awar e Deep Belief Network Representa tions for Multimodal Unsuper-\nvised Deception Detecti on. Proc\u20142021 16th IEEE Int Conf Autom Face Gesture Recognition , FG\n2021. 2021;\n60. Yang JT, Liu GM, Huang SCH. Emotion Transfor mation Feature : Novel Feature for Deception Detec-\ntion in Videos. In: Procee dings\u2014Interna tional Conferen ce on Image Processin g, ICIP. 2020. p. 1726\u2013\n30.\n61. Rajoub BA, Zwiggelaa r R. Thermal Facial Analysis for Deception Detection. IEEE Trans Inf Forensics\nSecur. 2014; 9(6):1015\u2013 23.\n62. Nasri H, Ouarda W, Alimi AM. ReLiDSS: Novel lie detection system from speech signal. Proc IEEE/\nACS Int Conf Comput Syst Appl AICCSA. 2016; 0.\n63. Velichko AN, Karpov AA. Automatic Detection of Decep tive and Truthful Paralinguis tic Informatio n in\nSpeech using Two-Level Machine Learning Model. Komp\u2019jut ernaja Lingvistik a i Intellektual\u2019ny e Teh-\nnol. 2021; 2021-June(2 0):698\u2013704 .\n64. Karimi H, Tang J, Li Y. Toward End-to-En d Deception Detection in Videos. Proc\u20142018 IEEE Int Conf\nBig Data, Big Data 2018. 2019;(c) :1278\u201383.\n65. Karimi H. Interpreta ble multimodal deception detection in videos. ICMI 2018\u2014Pro c 2018 Int Conf Mul-\ntimodal Interact. 2018;511\u20135.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 28 / 31\n\n66. Khan W, Crockett K, O\u2019Shea J, Hussain A, Khan BM. Deception in the eyes of deceiver: A computer\nvision and machine learning based automated deception detection. Expert Syst Appl [Interne t]. 2021;\n169(Fe bruary 2020):11434 1. Availab le from: https://doi.o rg/10.1016/j.e swa.202 0.114341\n67. Thanno on HH, Ali WH, Hashim IA. Detection of Deception Using Facial Expressio ns Based on Differ-\nent Classificat ion Algorithms. 2018 3rd Sci Conf Electr Eng SCEE 2018. 2018;51 \u20136.\n68. Fan C, Zhao H, Chen X, Fan X, Chen S. Distinguis hing deception from non-decept ion in Chinese\nspeech. Proc 6th Int Conf Intell Control Inf Process ICICIP 2015. 2016;268\u201373.\n69. Sanau llah M, Gopalan K. Deception detection in speech using bark band and perceptually significant\nenergy features. Midwest Symp Circuits Syst. 2013;1212\u2013 5.\n70. Tao H, Lei P, Wang M, Wang J, Fu H. Speech Deception Detection Algorithm Based on SVM and\nAcoustic Features. Proc IEEE 7th Int Conf Comput Sci Netw Technol ICCSNT 2019. 2019;31\u20133.\n71. Dcosta M, Shastri D, Vilalta R, Burgoon JK, Pavlidi s I. Perinasal indicator s of deceptive behavio r. 2015\n11th IEEE Int Conf Work Autom Face Gestur e Recognition , FG 2015. 2015;\n72. Mbaziira A V., Murphy DR. An empirical study on detecting deception and cybercrime using artificial\nneural networks . ACM Int Conf Proceeding Ser. 2018;42 \u20136.\n73. Velichko A, Budkov V, Kagirov I, Karpov A. Comparative Analysis of Classifi cation Methods for Auto-\nmatic Decept ion Detection in Speech. In: Karpov A, Jokisch O, Potapo va R, editors. Speech and Com-\nputer. Cham: Springer Interna tional Publishing; 2018. p. 737\u201346.\n74. Jaiswal M, Tabibu S, Bajpai R. The Truth and Nothing but the Truth: Multimodal Analysis for Deception\nDetecti on. IEEE Int Conf Data Min Work ICDMW. 2016; 0:938\u20134 3.\n75. Levitan SI, Maredia A, Hirschberg J. Acoustic-pr osodic indicators of deception and trust in interview\ndialogu es. Proc Annu Conf Int Speech Commun Assoc INTERS PEECH. 2018;2018-S epte:416 \u201320.\n76. Kleinberg B, van der Toolen Y, Vrij A, Arntz A, Verschuere B. Automate d verbal credibi lity assessmen t\nof intentions: The model stateme nt technique and predicti ve modelin g. Appl Cogn Psych ol. 2018; 32\n(3):354\u201366 . https://doi.or g/10.1002/ acp.3407 PMID: 29861544\n77. Avola D, Foresti GL, Cinque L, Pannone D. Automatic deception detection in RGB videos using facial\naction units. ACM Int Conf Proceeding Ser. 2019;\n78. Kleinberg B, Verschue re B. How humans impair automated deception detection performanc e. Acta\nPsych ol (Amst) [Internet ]. 2021; 213(Ma rch 2020):10325 0. Availab le from: https://doi.o rg/10.1016/j.\nactpsy.2 020.103250 PMID: 33450692\n79. Raima n N, Hung H, Englebienn e G. Move, and I will tell you who you are: Detecting deceptive roles in\nlow-qua lity data. ICMI\u201911\u2014Pr oc 2011 ACM Int Conf Multimo dal Interact. 2011;20 1\u20134.\n80. Mathur L, Matari\u0107 MJ. Unsupervised Audio-Visu al Subspa ce Alignme nt for High-Stak es Deception\nDetecti on. Proc\u20142021 IEEE Int Conf Acoust Speech Signal Process ICASSP 2021. 2021;225 5\u20139.\n81. Xie Y, Liang R, Tao H, Zhu Y, Zhao L. Convolution al bidirection al long short-te rm memory for decep-\ntion detection with acoustic feature s. IEEE Access. 2018; 6:76527\u201334.\n82. Chou HC, Liu YW, Lee CC. Joint learning of conversatio nal temporal dynamic s and acoustic feature s\nfor speech deception detection in dialog games. 2019 Asia-Pacific Signal Inf Process Assoc Annu\nSummit Conf APSIPA ASC 2019. 2019;(Nove mber):1044\u20135 0.\n83. Orshe a J, Crockett K, Khan W, Kindynis P, Antoniades A, Boultad akis G. Intelligent Deception Detec-\ntion through Machine Based Interviewing . Proc Int Jt Conf Neural Networ ks. 2018;2018-Jul y.\n84. Gonzal ez-Billando n J, Aroyo AM, Tonelli A, Pasqua li D, Sciutti A, Gori M, et al. Can a Robot Catch\nYou Lying? A Machine Learning System to Detect Lies During Interactio ns. Front Robot AI. 2019; 6\n(July):1\u2013 12. https://doi. org/10.3389/fr obt.2019 .00064 PMID: 335010 79\n85. Mihalcea R, Pe \u00b4 rez-Rosas V, Burzo M. Automatic detection of deceit in verbal communic ation. ICMI\n2013\u2014 Proc 2013 ACM Int Conf Multimodal Interact. 2013;131\u20134.\n86. Pe \u00b4 rez-Rosa s V, Abouelenie n M, Mihalcea R, Burzo M. Deception detection using real-life trial data.\nICMI 2015\u2014Pro c 2015 ACM Int Conf Multimodal Interact. 2015;59 \u201366.\n87. Pasqua li D, Gonzal ez-Billando n J, Aroyo AM, Sandini G, Sciutti A, Rea F. Detecti ng Lies is a Child\n(Robot)\u2019 s Play: Gaze-Based Lie Detection in HRI. Int J Soc Robot [Internet]. 2021; Available from:\nhttps:// doi.org/10.10 07/s1236 9-021-008 22-5\n88. Fan X, Zhao H, Chen X, Fan C, Chen S. Decept ive Speech Detecti on based on sparse representatio n.\nProcee ding\u20142016 IEEE 12th Int Colloq Signal Process its Appl CSPA 2016. 2016;(Marc h):7\u201311.\n89. Sen UM, Perez-Ros as V, Yanikoglu B, Aboue lenien M, Burzo M, Mihalcea R. Multimo dal Deception\nDetecti on using Real-Life Trial Data. IEEE Trans Affect Comput. 2020; 3045(c) :1\u201314.\n90. Ngo LM, Wang W, Mandira B, Karaoglu S, Bouma H, Dibekliogl u H, et al. Identity unbiased deception\ndetection by 2d-to-3d face reconstru ction. Proc\u2014 2021 IEEE Winter Conf Appl Comput Vision, WACV\n2021. 2021;145\u201354.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 29 / 31\n\n91. Fornacia ri T, Poesio M. On the use of homogenous sets of subjects in deceptive language analysis.\nComp ut Linguist Proc Work Comput Approac hes to Decept Detect. 2012;39\u201347.\n92. Levitan SI, Maredia A, Hirschberg J. Linguisti c cues to deception and perceived deception in interview\ndialogu es. NAACL HLT 2018\u20132018 Conf North Am Chapter Assoc Comput Linguist Hum Lang Tech-\nnol\u2014Proc Conf. 2018; 1:1941\u201350.\n93. Bai C, Bolonkin M, Burgoon J, Chen C, Dunbar N, Singh B, et al. Automatic long-term deception detec-\ntion in group interacti on videos. Proc\u2014IEEE Int Conf Multimed Expo. 2019;2019-Jul y:1600\u20135 .\n94. Bailey J, Demyan ov S, Ramamo hanarao K, Leckie C. Detecti on of deception in the Mafia party game.\nICMI 2015\u2014Pro c 2015 ACM Int Conf Multimodal Interact. 2015;33 5\u201342.\n95. Almela A\n\u00b4\n, Valencia-G arc\u0131 \u00b4 a R, Cantos P. Seeing through Decept ion: A Computationa l Approach to\nDeceit Detection in Spanish Written Communic ation. Linguist Evid Secur Law Intell. 2013; 1(1):3\u201312.\n96. Aboue lenien M, Pe \u00b4 rez-Rosas V, Mihalcea R, Burzo M. Deception detection using a multimodal\napproac h. ICMI 2014\u2014 Proc 2014 Int Conf Multimodal Interact. 2014;58\u201365.\n97. Kamboj M, Hessler C, Asnani P, Riani K, Abouelenie n M. Multimodal Political Deception Detecti on.\nIEEE Multimed. 2021; 28(1):94\u20131 02.\n98. Islam S, Saha P, Chowd hury T, Sorowa r A, Rab R. Non-invasiv e Deception Detection in Videos Using\nMachine Learning Techniqu es. 2021 5th Int Conf Electr Eng Inf Commun Technol ICEEICT 2021.\n2021.\n99. Pe \u00b4 rez-Rosa s V, Mihalcea R. Experi ments in open domain deception detection. Conf Proc\u2014EMN LP\n2015 Conf Empir Methods Nat Lang Process. 2015;(Septe mber):1120\u2013 5.\n100. Litvinova O, Litvinova T, Seredin P, Lyell J. Deception detection in Russian texts. 15th Conf Eur Chap-\nter Assoc Comp ut Linguist EACL 2017\u2014Pro c Student Res Work. 2017;43 \u201352.\n101. Rill-Ga rcia R, Escalante HJ, Villasen or-Pineda L, Reyes- Meza V. High-level feature s for multimodal\ndeception detection in videos. IEEE Comput Soc Conf Comput Vis Pattern Recognit Work.\n2019;20 19-June:156 5\u201373.\n102. Hosomi N, Sakti S, Yoshino K, Nakamu ra S. Deception Detection and Analysis in Spoken Dialogue s\nbased on FastText . 2018 Asia-Pacific Signal Inf Process Assoc Annu Summit Conf APSIPA ASC\n2018\u2014 Proc. 2019;(No vember):1 39\u201342.\n103. Aboue lenien M, Pe \u00b4 rez-Rosas V, Zhao B, Mihalcea R, Burzo M. Gender-b ased multimod al deception\ndetection. Proc ACM Symp Appl Comput . 2017;Part F1280:13 7\u201344.\n104. Gupta V, Agarwal M, Arora M, Chakrabor ty T, Singh R, Vatsa M. Bag-of-lie s: A multimodal dataset for\ndeception detection. IEEE Comput Soc Conf Comp ut Vis Pattern Recognit Work. 2019;2019-\nJune:83\u2013 90.\n105. Levitan SI, An G, Wang M, Mendels G, Hirschberg J, Levine M, et al. Cross-cultur al productio n and\ndetection of deception from speech. WMDD 2015\u2014Pro c ACM Work Multimod al Decep t Detect co-\nlocated with ICMI 2015. 2015;1\u2013 8.\n106. Hu S. Detecting concealed informati on in text and speech. ACL 2019\u201457 th Annu Meet Assoc Comp ut\nLinguist Proc Conf. 2020;402\u2013 12.\n107. Rubin VL, Conroy N. Discerning truth from deception : Human judgmen ts and automatio n efforts. First\nMonday. 2012; 17(3).\n108. Rubin VL, Conroy NJ. Challeng es in automated deception detection in computer-m ediated commun i-\ncation. Proc ASIST Annu Meet. 2011; 48.\n109. Rybar M, Bielikova M. Automate d detection of user deception in on-line questionnaire s with focus on\neye tracking use. Proc\u201411t h Int Work Semant Soc Media Adapt Pers SMAP 2016. 2016;(i):24\u2013 8.\n110. Mendels G, Levitan SI, Lee KZ, Hirsch berg J. Hybrid acoustic-lexi cal deep learning approa ch for\ndeception detection. Proc Annu Conf Int Speech Commun Assoc INTERS PEECH. 2017;2017-\nAugus:14 72\u20136.\n111. Fu H, Lei P, Tao H, Zhao L, Yang J. Improved semi-supe rvised autoenco der for deception detection.\nPLoS One [Interne t]. 2019; 14(10):1\u20131 3. Available from: http://dx .doi.org/10.13 71/journal. pone.\n022336 1 PMID: 31593570\n112. Speth J, Vance N, Czajka A, Bowyer KW, Wright D, Flynn P. Decept ion detection and remote physio-\nlogical monitoring: A dataset and baseline experiment al results. 2021 IEEE Int Jt Conf Biometric s,\nIJCB 2021. 2021.\n113. Aboue lenien M, Mihalcea R, Burzo M. Analyzing thermal and visual clues of deception for a non-con-\ntact deception detection approach. ACM Int Conf Proceeding Ser. 2016;29 -June-20:1\u20134 .\n114. Warnita T, Lestari DP. Construc tion and analysis of Indonesia n-interview s deception corpus. 2017\n20th Conf Orient Chapter Int Comm Coord Stand Speech Databases Assess Tech O-COCOSD A\n2017. 2018;(Nove mber):1\u20136.\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 30 / 31\n\n115. Hershk ovitch Neiterman E, Bitan M, Azaria A. Multiling ual Deception Detectio n by Autonom ous\nAgents. Web Conf 2020\u2014 Companion World Wide Web Conf WWW 2020. 2020;480\u20134.\n116. Takabatak e S, Shimada K, Saitoh T. Construction of a liar corpus and detection of lying situations.\nProc\u2014 2018 Jt 10th Int Conf Soft Comput Intell Syst 19th Int Symp Adv Intell Syst SCIS-ISIS 2018.\n2018;97 1\u20136.\n117. Kopev D, Ali A, Koychev I, Nakov P. Detecting Decep tion in Political Debates Using Acoustic and Tex-\ntual Features. 2019 IEEE Autom Speech Recognit Underst Work ASRU 2019\u2014 Proc. 2019;652\u20139.\n118. Rama naiah N V, Byravan A, Detwiler FRJ. Revised Neo Person ality Inventory Profiles of Machiav el-\nlian and Non-Mac hiavellian People. Psychol Rep [Internet ]. 1994; 75(2):937\u2013 8. Availab le from: https://\ndoi.org /10.2466/pr0.1 994.75.2 .937\n119. Jakobw itz S, Egan V. The dark triad and normal persona lity traits. Pers Individ Dif. 2006; 40(2):331\u2013 9.\n120. Suchotzk i K, Gamer M. Effect of negative motivation on the behavio ral and autonomi c correlates of\ndeception . Psychophy siology. 2019; 56(1):1\u201311 . https://doi. org/10.1111/p syp.13284 PMID: 30187497\n121. Chung CK, Pennebaker JW. Linguisti c Inquiry and Word Count (LIWC). Appl Nat Lang Process. 2013;\n(April):2 06\u201329.\n122. Tomas h JJ, Reed P. Using condition ing to elicit skin conductance response s to deception. Learn Motiv\n[Interne t]. 2015; 49:31\u20137. Available from: http://dx.doi.o rg/10.1 016/j.lmot.2 015.02.00 2\n123. Xu F, Uszkoreit H, Du Y, Fan W, Zhao D, Zhu J. Explain able AI: A Brief Survey on History, Research\nAreas, Approaches and Challenges . Lect Notes Comp ut Sci (including Subser Lect Notes Artif Intell\nLect Notes Bioinform atics). 2019; 11839 LNAI:563\u2013 74.\n124. Mu \u00a8 ller AC, Guido S. Introducti on to Machine Learning with Python\u2014A guide for Data Scientists. 1st\ned. Hands-on Machine Learning with Python. Sebastop ol: O\u2019Reilly Media, Inc; 2016. 65\u201377 p.\n125. Yu X, Zhang S, Yan Z, Yang F, Huang J, Dunbar NE, et al. Is interactional dissynch rony a clue to\ndeception ? Insights from automated analysis of nonverbal visual cues. IEEE Trans Cybern. 2015; 45\n(3):492\u201350 6. https://doi.or g/10.1109/ TCYB.201 4.2329673 PMID: 249886 00\nPLOS ONE\nDeception detection with machine learning: A systematic review and statistic al analysis\nPLOS ONE | https://doi.or g/10.137 1/journal.po ne.02813 23 February 9, 2023 31 / 31",
  "metadata": {
    "title": "Deception detection with machine learning: A systematic review and statistical analysis",
    "author": "Alex Sebasti\u00e3o Const\u00e2ncio, Denise Fukumi Tsunoda, Helena de F\u00e1tima Nunes Silva, Jocelaine Martins da Silveira, Deborah Ribeiro Carvalho",
    "pages": 31,
    "source_file": "Const\u00e2ncio_2023_Deception_detection_with_machine.pdf",
    "pdf_library": "pypdf"
  },
  "page_mapping": {
    "0": [
      1,
      0,
      4049
    ],
    "4049": [
      2,
      4049,
      8133
    ],
    "8133": [
      3,
      8133,
      12166
    ],
    "12166": [
      4,
      12166,
      16230
    ],
    "16230": [
      5,
      16230,
      20297
    ],
    "20297": [
      6,
      20297,
      22674
    ],
    "22674": [
      7,
      22674,
      25473
    ],
    "25473": [
      8,
      25473,
      27768
    ],
    "27768": [
      9,
      27768,
      31109
    ],
    "31109": [
      10,
      31109,
      32233
    ],
    "32233": [
      11,
      32233,
      34891
    ],
    "34891": [
      12,
      34891,
      38903
    ],
    "38903": [
      13,
      38903,
      42727
    ],
    "42727": [
      14,
      42727,
      46212
    ],
    "46212": [
      15,
      46212,
      50325
    ],
    "50325": [
      16,
      50325,
      54162
    ],
    "54162": [
      17,
      54162,
      58154
    ],
    "58154": [
      18,
      58154,
      62132
    ],
    "62132": [
      19,
      62132,
      66258
    ],
    "66258": [
      20,
      66258,
      70306
    ],
    "70306": [
      21,
      70306,
      74329
    ],
    "74329": [
      22,
      74329,
      78072
    ],
    "78072": [
      23,
      78072,
      82169
    ],
    "82169": [
      24,
      82169,
      85434
    ],
    "85434": [
      25,
      85434,
      88172
    ],
    "88172": [
      26,
      88172,
      91882
    ],
    "91882": [
      27,
      91882,
      96878
    ],
    "96878": [
      28,
      96878,
      101553
    ],
    "101553": [
      29,
      101553,
      106893
    ],
    "106893": [
      30,
      106893,
      111665
    ],
    "111665": [
      31,
      111665,
      114062
    ]
  }
}