{
  "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
  "metadata": {
    "title": "",
    "author": "",
    "pages": 6,
    "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
    "pdf_library": "pypdf"
  },
  "num_chunks": 32,
  "chunks": [
    {
      "text": "ArCOV19-Rumors [13] No false, true, other 9.4k Imbalanced bigIR\nGitlab\n3\nEnglish\nGDD [37] No false, true > 50k Imbalanced Zenodo 4\nFacebook Misinformation No Misinformation 529 One label SurgeAI 5\nYelp Reviews No Genuine (1)\nFake (-1) 35.9k Imbalanced Kaggle 6\nAmazon Fake Reviews [16] No Spam (1)\nNot Spam (0) 26.7M Imbalanced Kaggle 7\nGenerated Fake Reviews [29] Yes generated\nreal 40k Balanced OSF8\nJapanese Hate Speech,\nInsults, and Toxicity No Toxic\nNot Toxic 1k Balanced SurgeAI 9\nSpanish Hate Speech No Toxic\nNot Toxic 1k Balanced SurgeAI 10\nGreek elAprilFoolsCorpus [25] No Deceptive\nTruthful 508 Balanced Gitlab 11\nMultilingual Fake News [22] No Fake News\nTruthful > 11k Imbalanced Gitlab12\n1 https://www.surgehq.ai/datasets/arabic-hate-speech-dataset\n2 https://gitlab.com/araieval/wanlp2023_araieval/-/tree/main/task2\n3 https://gitlab.com/bigirqu/ArCOV-19/-/tree/master/ArCOV19-Rumors\n4 https://zenodo.org/record/6512468\n5 https://www.surgehq.ai/datasets/facebook-misinformation-dataset\n6 https://www.kaggle.com/datasets/abidmeeraj/yelp-labelled-dataset\n7 https://www.kaggle.com/datasets/naveedhn/amazon-product-review-spam-and-non-spam\n8 https://osf.io/tyue9/#!",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p5_c0",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 5,
      "chunk_index": 0,
      "section": "3.9k",
      "char_start": 22326,
      "char_end": 23498,
      "prev_chunk_id": null,
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p5_c1",
      "semantic_coherence": 0.0,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "9 https://app.surgehq.ai/datasets/japanese-toxicity\n10 https://www.surgehq.ai/datasets/spanish-hate-speech-dataset\n11 https://gitlab.isl.ics.forth.gr/papanton/elaprilfoolcorpus\n12 https://github.com/bigheiniu/MM-COVID\nfound unclear and contradictory results and concluded there\nwas no evidence of deception\u2019s stylistic trace. On the other\nhand, a more recent publication by [37] found evidence to\nthe contrary insofar as DD within the text. Other substantial\nchallenges include:",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p5_c1",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 5,
      "chunk_index": 1,
      "section": "3.9k",
      "char_start": 23499,
      "char_end": 23977,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p5_c0",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p5_c2",
      "semantic_coherence": 0.5669442415237427,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "has been defined using the intent of the deceiver, but\nthe attacker is elusive in the real world, so intentions\nare impossible to access. We point the reader to [33]\nfor a new definition and taxonomy.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c2",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 2,
      "section": "1. Defining deception computationally. So far, deception",
      "char_start": 25640,
      "char_end": 25840,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c1",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c3",
      "semantic_coherence": 0.3591802418231964,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "and useful to guide further research. For example, the\ntaxonomy should help build a quality general deception\ndataset and then generalized deception detection mod-\nels. Making sure it is high quality can also be a chal-\nlenge (but see [35, 5]).",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c3",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 3,
      "section": "2. Giving a taxonomy for deception that is comprehensive",
      "char_start": 26156,
      "char_end": 26400,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c2",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c4",
      "semantic_coherence": 0.41874244809150696,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "deception.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c4",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 4,
      "section": "3. Finding a common basis for the different forms of",
      "char_start": 26760,
      "char_end": 26770,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c3",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c5",
      "semantic_coherence": 0.44692933559417725,
      "has_citations": false,
      "topic_cluster": 0
    },
    {
      "text": "the different forms of deception. Some evidence is\nreported in [33].",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c5",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 5,
      "section": "4. Finding common linguistic cues and invariants across",
      "char_start": 26888,
      "char_end": 26956,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c4",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c6",
      "semantic_coherence": 0.7059028744697571,
      "has_citations": true,
      "topic_cluster": 0
    },
    {
      "text": "their nature, would be targeted, e.g., spearphishing, or\noverly broad, such as spam or phishing. This gives rise\nto imbalanced scenarios. An adapter, Prexia, is reported\nin [2].",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c6",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 6,
      "section": "5. Dealing with imbalanced data. Deceptive attacks, by",
      "char_start": 27138,
      "char_end": 27315,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c5",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c7",
      "semantic_coherence": 0.2839198112487793,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "fortable sharing sensitive information, such as targeted\nattacks (spearphishing). Can we design models that can\nwork with limited shared data?",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c7",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 7,
      "section": "6. Distributed nature. People and companies are uncom-",
      "char_start": 27604,
      "char_end": 27746,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c6",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c8",
      "semantic_coherence": 0.2426384836435318,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "ability? Can humans improve the detector\u2019s ability with\njust a few examples? Or by providing access to his/her\ncognitive load through a sensor? 5 Defining Success\nIdeally, we would achieve a deception detection model that\ndoes not need any labeled data to detect new attacks since it\nis based on invariants of deception. However, this may be\ntoo difficult a holy grail to achieve. Thus, success would be\na detector that helps the human in the loop do significantly\nbetter at resisting attacks (e.g., a novice email user can\ndetect quite sophisticated spearphishing attacks).",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c8",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 8,
      "section": "7. Human in the loop. Can the detector improve human",
      "char_start": 28002,
      "char_end": 28576,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c7",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c9",
      "semantic_coherence": 0.2224019318819046,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "If we can\nachieve this goal, then we can start researching the problem\nof building teachable detectors so that the human and the\ndetector can improve each other. 6 Possible Solution\nIn this section, we present a preliminary solution to address\nthe problem outlined in this work. Our proposed approach\nleverages the power of advanced, large-scale, multilingual,\nand multimodal contextual learners, complemented by Re-\ntrieval Augmented Generation (RAG). It is important to note\nthat this approach is just one of several promising avenues\nthat warrant further exploration.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c9",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 9,
      "section": "7. Human in the loop. Can the detector improve human",
      "char_start": 28577,
      "char_end": 29147,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c8",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c10",
      "semantic_coherence": 0.32772740721702576,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "To lay the foundation for a potential solution, we ini-\ntially focus on a single modality, namely text. In this con-\nfiguration, we aim to create a system capable of identifying\ndeceptive text in a domain-agnostic and multilingual con-\ntext. To ensure the system\u2019s relevance and effectiveness,\nwe aim to imbue it with desirable attributes, including result\nexplainability and robust zero to few-shot performance. To\nachieve these characteristics, a logical system design might\ninvolve the integration of an exceptionally large-scale lan-\nguage model that excels in contextual learning, such as Mis-\ntral [17].",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c10",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 10,
      "section": "7. Human in the loop. Can the detector improve human",
      "char_start": 29148,
      "char_end": 29757,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c9",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c11",
      "semantic_coherence": 0.41286078095436096,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "This model can achieve superior performance in\nthe task, regardless of the domain, and remains resilient in\nthe face of diverse data distributions. To further enhance its\nexplainability, the model can undergo instruction tuning, en-\nabling it to deliver answers and elucidate its underlying rea-\nsoning. To elevate its already outstanding zero to few-shot capa-\nbilities and achieve performance parity with fully fine-tuned\nspecialized models in specific domains, it is advisable to\naugment the learner with a Retrieval Augmented Generation\n(RAG) infrastructure, as proposed by [19].",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c11",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 11,
      "section": "7. Human in the loop. Can the detector improve human",
      "char_start": 29758,
      "char_end": 30341,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c10",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c12",
      "semantic_coherence": 0.4216199815273285,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "This design de-\ncision ensures the longevity of the system and its\u2019 ability to\nstay up-to-date with current threats because it makes contin-\nuous finetuning unnecessary. A standard RAG system\u2019s high-level system design\nscheme is shown in Figure 1. It consists of mining-derived\ndatasets indexed and stored in a vector database, accessed\nthrough FAISS [7] (Facebook AI Similarity Search) or any\nother approximate nearest neighbors algorithm optimized for\nsearching large vector spaces. Combined with Retrieval-\nAugmented Generation (RAG) techniques [19], this infras-\ntructure delivers critical context to enhance Mistral\u2019s perfor-\nmance.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c12",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 12,
      "section": "7. Human in the loop. Can the detector improve human",
      "char_start": 30342,
      "char_end": 30979,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c11",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c13",
      "semantic_coherence": 0.45670729875564575,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "This system design is a decision-making tool that\ndetects deceptive text followed by a clear explanation of this\ndecision. Moreover, enhancing the LLM input prompt with\nretrieved context guarantees the model has all the necessary\ninformation to generate a comprehensive response. When presented with a single instance of a task, typi-\ncally a query from a user, the steps in solving the problem\n(each step is referenced in Figure 1 as (1),(2),(3), or (4)) are:",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c13",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 13,
      "section": "7. Human in the loop. Can the detector improve human",
      "char_start": 30980,
      "char_end": 31440,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c12",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c14",
      "semantic_coherence": 0.26381349563598633,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "initial prompt with the context retrieved from the Vector\nStore, creating an enriched input for the LLM.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c15",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 15,
      "section": "2. Augment Prompt with Retrieved Context: Merges the",
      "char_start": 35098,
      "char_end": 35202,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c14",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c16",
      "semantic_coherence": 0.0472269207239151,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "enhanced prompt.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c16",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 16,
      "section": "3. Send Augmented Prompt to LLM:The LLM receives the",
      "char_start": 35414,
      "char_end": 35430,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c15",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c17",
      "semantic_coherence": 0.41566312313079834,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "mented prompt, it generates its response. Figure 1: High-level overview of a possible solution using\nRAG and a multi-modal in-context learner. The dashed line\ndepicts the retrieval of context and its integration into the\nquery. A multimodal LLM is necessary to extend this approach\nto multiple modalities, e.g., a unified multimodal model, or\nUnIV AL [32], which unifies text, images, video, and audio\ninto a single model. Thus, it may be possible to use UnIV AL,\nor other multimodal models such as OPENAI\u2019s CLIP 4, in\n4https://www.pinecone.io/learn/series/\nimage-search/clip/\n\nplace of a single-mode model like Mistral [17].",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c17",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 17,
      "section": "4. Receive LLM\u2019s Response: After processing the aug-",
      "char_start": 35554,
      "char_end": 36179,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c16",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c18",
      "semantic_coherence": 0.34940195083618164,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "In addition,\nother components, such as RAG, may need to be adjusted\nas needed. However, most problems to be solved are in the\nengineering space. From a research perspective, the main challenge in de-\nsigning and implementing a functional system as described\nis model performance as a function of model size and the\ncurrent lack of multimodal in-context learners that are large\nenough to perform satisfactorily.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c18",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 18,
      "section": "4. Receive LLM\u2019s Response: After processing the aug-",
      "char_start": 36180,
      "char_end": 36590,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c17",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c19",
      "semantic_coherence": 0.35268789529800415,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "For text, we notice that\nmodels of 2-3B parameters score 0.25 or so on the Hugging-\nFace LLM benchmark, 7B score 0.73, and 170B score 0.75;\nin other words, there is a massive jump from 3B to 7B pa-\nrameters followed by a plateau. So, to have a truly intelli-\ngent model, it needs to be at least 7B for a single modality,\nas a rule of thumb - although it may be possible to bring\nthis number down through quantization and other means. Multiple modalities may require larger models for similar\nperformance.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c19",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 19,
      "section": "4. Receive LLM\u2019s Response: After processing the aug-",
      "char_start": 36591,
      "char_end": 37095,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c18",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c20",
      "semantic_coherence": 0.3947446644306183,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "Currently, UnIV AL has only 0.25B parame-\nters. Therefore, we hypothesize that such a system as we\ndescribed would be made possible by an advance in models\nlike UnIV AL - multimodal transformers that learn in context\nand have billions of parameters. Perhaps, Flamingo with 80B\nparameters [1] can help here. 7 Conclusions\nIn this paper, we introduce a new concept \u201cMultilingual,\nMultimodal Domain-independence Deception Detection\u201d\nthat unifies diverse investigations, creating a new paradigm\nfor detecting deceitful behavior across languages and modal-\nities.\n\nThis innovative approach harmoniously connects pre-\nvious research in multimodal and cross-lingual deception de-\ntection, paving the way for future breakthroughs. We discuss\nthe research challenges related to this concept and also po-\ntential solutions. Acknowledgments. Research partly supported by NSF grants 2210198\nand 2244279, and ARO grants W911NF-20-1-0254 and\nW911NF-23-1-0191. Verma is the founder of Everest Cy-\nber Security and Analytics, Inc.\nReferences\n[1] J.-B. A LAYRAC , J. D ONAHUE , P. L UC, A. M IECH ,\nI. B ARR , Y. H ASSON , K. L ENC , A. M ENSCH , K.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c20",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 20,
      "section": "4. Receive LLM\u2019s Response: After processing the aug-",
      "char_start": 37096,
      "char_end": 38228,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c19",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c21",
      "semantic_coherence": 0.22073742747306824,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "M IL-\nLICAN , M. R EYNOLDS , R. R ING , E. R UTHERFORD ,\nS. C ABI , T. H AN, Z. G ONG , S. S AMANGOOEI , M. M ON-\nTEIRO , J. M ENICK , S. B ORGEAUD , A. B ROCK , A. N E-\nMATZADEH , S. S HARIFZADEH , M. B INKOWSKI , R. B AR-\nREIRA , O. V INYALS , A. Z ISSERMAN , AND K. S IMONYAN ,\nFlamingo: a visual language model for few-shot learning ,",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c21",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 21,
      "section": "4. Receive LLM\u2019s Response: After processing the aug-",
      "char_start": 38228,
      "char_end": 38566,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c20",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c22",
      "semantic_coherence": 0.27764585614204407,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "Domain-agnostic adapter architecture for deception detec-\ntion: Extensive evaluations with the difraud benchmark , in\nJoint International Conference on Computational Linguistics,\nLanguage Resources and Evaluation, Torino, Italy, May 2024,\nEuropean Language Resources Association. [3] P. C APUOZZO , I. L AURIOLA , C. S TRAPPARAVA ,\nF. A IOLLI , AND G. S ARTORI , Decop: A multilingual\nand multi-domain corpus for detecting deception in typed\ntext, in Proceedings of the Twelfth Language Resources and\nEvaluation Conference, 2020, pp. 1423\u20131430. [4] W. C ERON , M.-F. DE LIMA -SANTOS , AND M. G.\n\nQ UILES ,\nFake news agenda in the era of covid-19: Identifying trends\nthrough fact-checking content. online social networks and\nmedia, 21, 100116, 2020. [5] V. M. H. D ANG AND R. M. V ERMA , Data quality in\nNLP: Metrics and a comprehensive taxonomy , in Interna-\ntional Symposium on Intelligent Data Analysis, Springer,\n2024, pp. 217\u2013229. [6] J. D EVLIN , M.-W. C HANG , K. L EE, AND K. T OUTANOVA ,\nBert: Pre-training of deep bidirectional transformers for\nlanguage understanding, 2019. [7] M. D OUZE , A. G UZHVA , C. D ENG , J.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c22",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 22,
      "section": "2022.\n[2] D. B OUMBER , F. Z. Q ACHFAR , AND R. M. V ERMA ,",
      "char_start": 41686,
      "char_end": 42812,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c21",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c23",
      "semantic_coherence": 0.21259161829948425,
      "has_citations": true,
      "topic_cluster": 1
    },
    {
      "text": "J OHNSON ,\nG. S ZILVASY, P.-E. M AZAR \u00b4E, M. L OMELI , L. H OS-\nSEINI , AND H. J \u00b4EGOU , The faiss library , arXiv preprint\narXiv:2401.08281, (2024). [8] A. E L AASSAL , S. B AKI , A. D AS, AND R. M. V ERMA ,\nAn in-depth benchmarking and evaluation of phishing de-\ntection research for security needs , IEEE Access, 8 (2020),\npp. 22170\u201322192. [9] S. F ENG , R. B ANERJEE , AND Y. CHOI , Syntactic stylometry\nfor deception detection, in Annual Meeting of the Association\nfor Computational Linguistics, 2012.\n\n[10] M. G LENSKI , E. A YTON , R. C OSBEY , D. A RENDT , AND\nS. V OLKOVA, Towards trustworthy deception detection:\nBenchmarking model robustness across domains, modalities,\nand languages, in Proceedings of the 3rd International Work-\nshop on Rumours and Deception in Social Media (RDSM),\nBarcelona, Spain (Online), Dec. 2020, Association for Com-\nputational Linguistics, pp. 1\u201313. [11] T. G R \u00a8ONDAHL AND N. A SOKAN , Text analysis in adversar-\nial settings: Does deception leave a stylistic trace? , ACM\nComputing Surveys (CSUR), 52 (2019), pp. 1\u201336. [12] A. H AMID , N.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c23",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 23,
      "section": "2022.\n[2] D. B OUMBER , F. Z. Q ACHFAR , AND R. M. V ERMA ,",
      "char_start": 42812,
      "char_end": 43891,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c22",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c24",
      "semantic_coherence": 0.705755889415741,
      "has_citations": true,
      "topic_cluster": 1
    },
    {
      "text": "S HIEKH , N. S AID , K. A HMAD , A. G UL,\nL. H ASSAN , AND A. A L-FUQAHA , Fake news detection in\nsocial media using graph neural networks and nlp techniques:\nA covid-19 use-case , arXiv preprint arXiv:2012.07517,\n(2020). [13] F. H AOUARI , M. H ASANAIN , R. S UWAILEH , AND T. E L-\nSAYED , Arcov19-rumors: Arabic covid-19 twitter dataset for\nmisinformation detection, arXiv preprint arXiv:2010.08768,\n(2020). [14] M. H ASANAIN , F. A LAM , H. M UBARAK , S. A BDALJALIL ,\nW. Z AGHOUANI , P.\n\nN AKOV, G. D A SAN MARTINO , AND\nA. F REIHAT , Araieval shared task: Persuasion techniques\nand disinformation detection in arabic text , in Proceedings\nof the First Arabic Natural Language Processing Conference\n(ArabicNLP 2023), Singapore, Dec. 2023, Association for\n\nComputational Linguistics. [15] \u00b4A. H ERN \u00b4ANDEZ -CASTA \u02dcNEDA , H. C ALVO, A. G ELBUKH ,\nAND J. J. G. F LORES , Cross-domain deception detection\nusing support vector networks , Soft Computing, 21 (2017),\npp. 585\u2013595. [16] N. H USSAIN , H. T. M IRZA , I. H USSAIN , F.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c24",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 24,
      "section": "2022.\n[2] D. B OUMBER , F. Z. Q ACHFAR , AND R. M. V ERMA ,",
      "char_start": 43891,
      "char_end": 44918,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c23",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c25",
      "semantic_coherence": 0.49192726612091064,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "I QBAL ,\nAND I. M EMON , Spam review detection using the linguistic\nand spammer behavioral methods , IEEE Access, 8 (2020),\npp. 53801\u201353816. [17] A. Q. J IANG , A. S ABLAYROLLES , A. M ENSCH , C. B AM-\nFORD , D. S. C HAPLOT , D. DE LAS CASAS , F. B RESSAND ,\nG. L ENGYEL , G. L AMPLE , L. S AULNIER , L. R. L AVAUD,\nM.-A. L ACHAUX , P. S TOCK , T. L. S CAO , T. L AVRIL ,\nT. W ANG , T.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c25",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 25,
      "section": "2022.\n[2] D. B OUMBER , F. Z. Q ACHFAR , AND R. M. V ERMA ,",
      "char_start": 44918,
      "char_end": 45303,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c24",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c26",
      "semantic_coherence": 0.49623921513557434,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "L ACROIX , AND W. E. S AYED, Mistral 7b ,",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c26",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 26,
      "section": "2022.\n[2] D. B OUMBER , F. Z. Q ACHFAR , AND R. M. V ERMA ,",
      "char_start": 45304,
      "char_end": 45345,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c25",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c27",
      "semantic_coherence": 0.07111500948667526,
      "has_citations": false,
      "topic_cluster": -1
    },
    {
      "text": "Publications, 2014. [19] P. L EWIS , E. P EREZ , A. P IKTUS , F. P ETRONI ,\nV. K ARPUKHIN , N. G OYAL, H. K \u00a8UTTLER , M. L EWIS ,\nW. TAU YIH, T. R OCKT \u00a8ASCHEL , S. R IEDEL , AND\nD. K IELA , Retrieval-augmented generation for knowledge-\nintensive nlp tasks, 2021. [20] H. L I, Z. C HEN , A. M UKHERJEE , B. L IU, AND J.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c27",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 27,
      "section": "2023.\n[18] T. R. L EVINE , Encyclopedia of Deception , vol. 2, Sage",
      "char_start": 49126,
      "char_end": 49445,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c26",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c28",
      "semantic_coherence": 0.10742820054292679,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "S HAO,\nAnalyzing and detecting opinion spam on a large-scale\ndataset via temporal and spatial patterns , in Proceedings of\nthe international AAAI conference on web and social media,\nvol. 9, 2015, pp. 634\u2013637. [21] J. L I, L. YANG , AND P. ZHANG , Shooting review spam with\na weakly supervised approach and a sentiment-distribution-\noriented method, Applied Intelligence, 53 (2022), pp. 10789\u2013",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c28",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 28,
      "section": "2023.\n[18] T. R. L EVINE , Encyclopedia of Deception , vol. 2, Sage",
      "char_start": 49446,
      "char_end": 49838,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c27",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c29",
      "semantic_coherence": 0.27278587222099304,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "multilingual and multimodal data repository for combating\ncovid-19 disinformation , arXiv preprint arXiv:2011.04088,\n(2020). [23] P. M EHDI GHOLAMPOUR AND R. M. V ERMA , Adversarial\nrobustness of phishing email detection models, in Proceedings\nof the 9th ACM International Workshop on Security and\nPrivacy Analytics, 2023, pp. 67\u201376. [24] A. M UKHERJEE , V. V ENKATARAMAN , B. L IU, AND N. S. GLANCE , What yelp fake review filter might be doing? ,\nProceedings of the International AAAI Conference on Web\nand Social Media, (2013). [25] K. P APANTONIOU , P. P APADAKOS , G.\n\nF LOURIS , AND\nD. P LEXOUSAKIS , Linguistic cues of deception in a multi-\nlingual april fools\u2019 day context, in Proceedings of the Eighth\nItalian Conference on Computational Linguistics, CLiC-it\n2021, Milan, Italy, January 26-28, 2022, E. Fersini, M. Pas-\nsarotti, and V . Patti, eds., vol. 3033 of CEUR Workshop Pro-\nceedings, CEUR-WS.org, 2021. [26] N. R EIMERS AND I. G UREVYCH , Sentence-bert: Sentence\nembeddings using siamese bert-networks, 2019. [27] Y. R EN AND D. J I, Neural networks for deceptive opinion\nspam detection: An empirical study , Information Sciences,\n385-386 (2017), pp. 213\u2013224. [28] R.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c29",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 29,
      "section": "10799.\n[22] Y. L I, B. J IANG , K. S HU, AND H. L IU, Mm-covid: A",
      "char_start": 50688,
      "char_end": 51872,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c28",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c30",
      "semantic_coherence": 0.5028747320175171,
      "has_citations": true,
      "topic_cluster": 1
    },
    {
      "text": "R ILL -GARC \u00b4IA, L. V ILLASE \u02dcNOR -PINEDA , V. R EYES -\nMEZA , AND H. J. E SCALANTE , From text to speech: A\nmultimodal cross-domain approach for deception detection ,\nin CV AUI/IWCF/MIPPSNA@ICPR, 2018. [29] J. S ALMINEN , C. K ANDPAL , A. M. K AMEL , S.- G. J UNG ,\nAND B. J. J ANSEN , Creating and detecting fake reviews of\nonline products, Journal of Retailing and Consumer Services,\n64 (2022), p. 102771. [30] J. S \u00b4ANCHEZ -JUNQUERA , L. V ILLASE \u02dcNOR -PINEDA , M. M.\n\nY G \u00b4OMEZ , P. R OSSO , AND E. S TAMATATOS, Masking\ndomain-specific information for cross-domain deception de-\ntection, Pattern Recognit. Lett., 135 (2020), pp. 122\u2013130. [31] S. S HAHRIAR , A. MUKHERJEE , AND O. GNAWALI, Improv-\ning phishing detection via psychological trait scoring, 2022. [32] M. S HUKOR , C. D ANCETTE , A. R AME , AND M. C ORD ,\nUnival: Unified model for image, video, audio and language\ntasks, Transactions on Machine Learning Research Journal,\n(2023). [33] R. M. V ERMA , N. D ERSHOWITZ , V. Z ENG , D.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c30",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 30,
      "section": "10799.\n[22] Y. L I, B. J IANG , K. S HU, AND H. L IU, Mm-covid: A",
      "char_start": 51872,
      "char_end": 52870,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c29",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c31",
      "semantic_coherence": 0.6842852234840393,
      "has_citations": true,
      "topic_cluster": -1
    },
    {
      "text": "B OUM -\nBER , AND X. L IU, Domain-independent deception: A\nnew taxonomy and linguistic analysis , arXiv preprint\narXiv:2402.01019, (2024). [34] R. M. V ERMA , N. D ERSHOWITZ , V. Z ENG , AND X. L IU,\nDomain-independent deception: Definition, taxonomy and\nthe linguistic cues debate, 2022. [35] R. M. V ERMA , V. Z ENG , AND H. FARIDI , Data quality for\nsecurity challenges: Case studies of phishing, malware and\nintrusion detection datasets, in Proceedings of the 2019 ACM\nSIGSAC Conference on Computer and Communications Se-\ncurity, 2019, pp. 2605\u20132607. [36] S.\n\nV OLKOVA , E. A YTON , D. L. A RENDT , Z. H UANG , AND\nB. H UTCHINSON , Explaining multimodal deceptive news\nprediction models, in International Conference on Web and\nSocial Media, 2019. [37] V. Z ENG , X. LIU, AND R. M. V ERMA , Does deception leave\na content independent stylistic trace? , in Proceedings of the\nTwelfth ACM Conference on Data and Application Security\nand Privacy, CODASPY \u201922, New York, NY , USA, 2022,\nAssociation for Computing Machinery, p. 349\u2013351. [38] W. Z HANG , Y. D U, T.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c31",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 31,
      "section": "10799.\n[22] Y. L I, B. J IANG , K. S HU, AND H. L IU, Mm-covid: A",
      "char_start": 52870,
      "char_end": 53932,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c30",
      "next_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c32",
      "semantic_coherence": 0.673141598701477,
      "has_citations": true,
      "topic_cluster": 1
    },
    {
      "text": "Y OSHIDA , AND Q. W ANG , Dri-\nrcnn: An approach to deceptive review identification using\nrecurrent convolutional neural network, Inf. Process. Manag.,\n54 (2018), pp. 576\u2013592.",
      "chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c32",
      "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
      "page": 6,
      "chunk_index": 32,
      "section": "10799.\n[22] Y. L I, B. J IANG , K. S HU, AND H. L IU, Mm-covid: A",
      "char_start": 53932,
      "char_end": 54107,
      "prev_chunk_id": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain_p6_c31",
      "next_chunk_id": null,
      "semantic_coherence": 0.4632130563259125,
      "has_citations": false,
      "topic_cluster": -1
    }
  ]
}