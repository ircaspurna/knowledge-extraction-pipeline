{
  "text": "A Roadmap for Multilingual, Multimodal Domain Independent Deception Detection*\nDainis Boumber\ndboumber@uh.edu\nRakesh M. Verma\nrmverma2@Central.UH.EDU\nFatima Zahra Qachfar\nfqachfar@uh.edu\nAbstract\nDeception, a prevalent aspect of human communication, has\nundergone a significant transformation in the digital age.\nWith the globalization of online interactions, individuals are\ncommunicating in multiple languages and mixing languages\non social media, with varied data becoming available in each\nlanguage and dialect. At the same time, the techniques for\ndetecting deception are similar across the board. Recent\nstudies have shown the possibility of the existence of uni-\nversal linguistic cues to deception across domains within the\nEnglish language; however, the existence of such cues in\nother languages remains unknown. Furthermore, the prac-\ntical task of deception detection in low-resource languages\nis not a well-studied problem due to the lack of labeled data.\nAnother dimension of deception is multimodality. For ex-\nample, a picture with an altered caption in fake news or\ndisinformation may exist. This paper calls for a compre-\nhensive investigation into the complexities of deceptive lan-\nguage across linguistic boundaries and modalities within the\nrealm of computer security and natural language processing\nand the possibility of using multilingual transformer models\nand labeled data in various languages to universally address\nthe task of deception detection.\n1 Introduction\nDeception is a complex and pervasive phenomenon with pro-\nfound implications for various domains, including security,\nlaw enforcement, healthcare, and human-computer interac-\ntion. Accurately identifying deception has long been a crit-\nical goal for researchers and practitioners alike. Traditional\nmethods for deception detection (DD) have primarily relied\non linguistic cues and textual analysis [34, 37]. A DD task\nis typically a binary classification problem, aiming to label\na statement as being deceptive or not. Less often, the goal\nis to categorize a statement as falling into one of the more\nor less deceptive categories. It is a problem of growing im-\nportance that is made more challenging by the need to build\ndifferent datasets and detectors for the ever-increasing vari-\nety of domains and tasks where deceptive language poses a\nthreat. However, these methods often fall short in the face\nof sophisticated deceivers who can manipulate language ef-\nfectively, leaving the task of deception detection far from\n*All authors are with the University of Houston\nfoolproof [23]. Recently, there has been a paradigm shift\ntowards more comprehensive and robust approaches to de-\nception detection, which leverage multimodal data sources.\nThis shift recognizes that deception is not confined to lan-\nguage alone and that individuals may convey deceptive in-\nformation through various channels, including speech, fa-\ncial expressions, body language, and by using different lan-\nguages1 Another frequently debated topic is the transfer of\nlinguistic cues of deception across domains and modalities.\nThe need for domain-independence in deception detection is\nparamount since there are many manifestations of deception.\nWe call for a holistic approach to deception detection,\nfocusing on integrating multimodal (multiple modes of com-\nmunication) and multilingual (cross-linguistic) data while\nmaintaining domain independence. We propose leveraging\ncutting-edge advances in natural language processing (NLP),\ncomputer vision, and machine learning (ML) to enhance\nthe accuracy and robustness of deception detection across\na wide array of applications and settings. The research in\nthis area must address several critical challenges in deception\ndetection, including integrating non-verbal cues from mul-\ntiple modalities (e.g., speech, facial expressions, gestures,\nimage/video attachments) and considering linguistic varia-\ntions across different languages. By developing a domain-\nindependent approach, we call for creating a versatile ap-\nproach that can be applied to diverse scenarios, from border\nsecurity and criminal investigations to healthcare diagnostics\nand online content moderation.\nThis paper will present the theoretical foundations of\nmultimodal multilingual deception detection through exist-\ning work and suggest the methodologies to be employed. We\naim to open a new direction of research that will usher valu-\nable insights into a comprehensive approach to deception de-\ntection that transcends linguistic and contextual boundaries,\nopening up new possibilities for enhancing trust, security,\nand decision-making across various domains.\n2 The Idea and Impetus\nHistory is replete with famous lies and deceptions. Examples\ninclude P. T. Barnum, Nicolo Machiavelli, Sun Tzu, Opera-\ntion Mincemeat, and the Trojan Horse [18]. A chronology\nof deception is included in [18]. More recently, the prolifer-\n1However, multilingual deception detection efforts are relatively few.\narXiv:2405.03920v1  [cs.CL]  7 May 2024\n\nation of deceptive attacks such as fake news, phishing, and\ndisinformation is rapidly eroding trust in Internet-dependent\nsocieties. The situation has deteriorated so much that 45% of\nthe US population believes the 2020 US election was stolen.2\nSocial media platforms have come under severe scrutiny\nregarding how they police content. Facebook and Google\npartner with independent fact-checking organizations that\ntypically employ manual fact-checkers. Things will only get\nworse with the advent of Large Language Models, such as\nChatGPT.\nNatural-language processing (NLP) and machine learn-\ning (ML) researchers have joined the fight by designing\nfake news, phishing, and other types of domain-specific de-\ntectors. Building single-domain detectors may be subopti-\nmal. Composing them sequentially requires more time, and\ncomposing them in parallel requires more hardware. More-\nover, building single-domain detectors means one can only\nreact to new forms of deception after they emerge. We\naim to stimulate research on domain-independent decep-\ntion. Unfortunately, research in this area is currently ham-\npered by the lack of computational definitions and taxonomy,\nhigh-quality datasets, and systematic approaches to domain-\nindependent deception detection. Thus, the results are nei-\nther generalizable nor reliable, leading to much confusion.\nBy domain independence, we mean that deception can have\nmany different goals and motivations, such as phishing, job\nscams, political lies, fake news, etc., not just different topi-\ncal content For example, in previous work, researchers used\n\u201cmulti-domain\u201d to refer to lies on abortion, the death penalty,\nor feelings about best friends (see related work in [3]).\nBelow, we briefly survey some of the work that has been\ndone on deception so far. Of course, there is a lot of work on\nphishing, fake news, etc., when considered in isolation. Still,\nthere are hardly any works on identifying common patterns\nin different deceptive attacks and some have even claimed\nthat there are no common linguistic cues of deception [11].\n3 Related Work\nIn the past few years, there have been several studies of ap-\nplying computational methods to deal with deception detec-\ntion in a single domain. For fake news, [4] used topic mod-\nels and [12] used Bag of Words (BoW) and BERT [6] em-\nbedding. The state of the art (SOTA) in phishing detection\nhas been dominated by classical supervised machine learn-\ning approaches and deep neural nets [8]. More recently,\nBERT [6], a character-level CNN, and sentence embeddings\nfrom Sentence-BERT (SBERT) [26] were used to find emails\nexhibiting psychological traits most dominant in phishing\ntexts [31]. In detecting opinion spam and fake reviews,\nweakly supervised graph networks have been recently used\n2https://www.surveymonkey.com/curiosity/\naxios-january-6-revisited .\nwith some success [21]. [9, 24, 20] used part-of-speech tags\nand context-free grammar parse trees, behavioral features,\nand spatial-temporal features, respectively. Neural network\nmethods for spam detection consider the reviews as input\nwithout specific feature extraction. In [27], authors used a\ngated recurrent neural network to study the contextual infor-\nmation of review sentences. DRI-RCNN [38] used a recur-\nrent network for learning the contextual information of the\nwords in the reviews. Several studies on cross-domain de-\nception detection have been published, as well [15, 28, 30].\nRecently, a quality domain-independent deception dataset\nwas introduced in [37], with the empirical evidence suggest-\ning that large language models such as BERT and RoBERTa\nperform well on individual tasks when fine-tuned on a com-\nbination of out of domain deceptive texts. Closer to our\nstated goals, [36] created a multi-modal deception detection\ntool that used early deep learning models and word embed-\ndings, although ultimately, the performance was not always\nrobust and it lacked domain-independence capabilities. Fi-\nnally, [10] propose a framework for evaluating the robustness\nof deception detection models across two domains (Twitter\nand Reddit), modalities (Text, images), and five languages.\nThe authors in [10] propose a framework to evaluate the\nrobustness of deception detection models in two domains\n(Twitter and Reddit), modalities (text, images), and five\nlanguages (English, French, German, Russian, and Spanish)\nhighlighting similar challenges. In our topic, we would\nlike to extend the investigation further to include domain-\nindependent deception instead of domain-specific models as\ndiscussed in [10].\nDatasets We recommend utilizing a range of deception\ndata sources to create a diverse and versatile dataset for\ntraining AI models in multilingual and multimodal deception\ndetection. A good starting point is provided in Table 1, where\nwe have emphasized multi-domain datastes, but this list is\nby no means complete or exhaustive, 3 and finding relevant\ndata is not a finite process; that is, more data should be\nadded as new datasets are found. This approach will help\nensure that models are not limited to a single language, or\na single modality, or a single domain, and can effectively\ndetect deception across different cultures, communication\nchannels, and domains.\n4 Challenges and Future Opportunities\nIn this section, we briefly discuss significant research chal-\nlenges and point out future research opportunities. One of\nthe main problems that makes this an open-ended idea is\nthe fact that there is no consensus on the transferability of\ndeceptive cues across domains, even within a single modal-\nity. For example, a recent review of deception literature [11]\n3Especially since there is a plethora of datasets for single domains such\nas fake news or disinformation.\n\nTable 1: Deception Detection Dataset Sources. Multi-domain datasets are in boldface font in the Description column.\nLanguage Description\nContains\nSynthetic\nData\nLabels Total\nSamples Distribution Source\nArabic\nHate Speech No Toxic\nNot Toxic 1k Balanced SurgeAI 1\nDisinformation Detection [14] No\ndisinfo\nno-disinfo > 19k\nImbalanced ArAIEval\nGitlab\n2\nRumor, Spam\nOffensive (OFF),\nHate Speech (HS)\n3.9k\nArCOV19-Rumors [13] No false, true, other 9.4k Imbalanced bigIR\nGitlab\n3\nEnglish\nGDD [37] No false, true > 50k Imbalanced Zenodo 4\nFacebook Misinformation No Misinformation 529 One label SurgeAI 5\nYelp Reviews No Genuine (1)\nFake (-1) 35.9k Imbalanced Kaggle 6\nAmazon Fake Reviews [16] No Spam (1)\nNot Spam (0) 26.7M Imbalanced Kaggle 7\nGenerated Fake Reviews [29] Yes generated\nreal 40k Balanced OSF8\nJapanese Hate Speech,\nInsults, and Toxicity No Toxic\nNot Toxic 1k Balanced SurgeAI 9\nSpanish Hate Speech No Toxic\nNot Toxic 1k Balanced SurgeAI 10\nGreek elAprilFoolsCorpus [25] No Deceptive\nTruthful 508 Balanced Gitlab 11\nMultilingual Fake News [22] No Fake News\nTruthful > 11k Imbalanced Gitlab12\n1 https://www.surgehq.ai/datasets/arabic-hate-speech-dataset\n2 https://gitlab.com/araieval/wanlp2023_araieval/-/tree/main/task2\n3 https://gitlab.com/bigirqu/ArCOV-19/-/tree/master/ArCOV19-Rumors\n4 https://zenodo.org/record/6512468\n5 https://www.surgehq.ai/datasets/facebook-misinformation-dataset\n6 https://www.kaggle.com/datasets/abidmeeraj/yelp-labelled-dataset\n7 https://www.kaggle.com/datasets/naveedhn/amazon-product-review-spam-and-non-spam\n8 https://osf.io/tyue9/#!\n9 https://app.surgehq.ai/datasets/japanese-toxicity\n10 https://www.surgehq.ai/datasets/spanish-hate-speech-dataset\n11 https://gitlab.isl.ics.forth.gr/papanton/elaprilfoolcorpus\n12 https://github.com/bigheiniu/MM-COVID\nfound unclear and contradictory results and concluded there\nwas no evidence of deception\u2019s stylistic trace. On the other\nhand, a more recent publication by [37] found evidence to\nthe contrary insofar as DD within the text. Other substantial\nchallenges include:\n1. Defining deception computationally. So far, deception\nhas been defined using the intent of the deceiver, but\nthe attacker is elusive in the real world, so intentions\nare impossible to access. We point the reader to [33]\nfor a new definition and taxonomy.\n2. Giving a taxonomy for deception that is comprehensive\nand useful to guide further research. For example, the\ntaxonomy should help build a quality general deception\ndataset and then generalized deception detection mod-\nels. Making sure it is high quality can also be a chal-\nlenge (but see [35, 5]).\n3. Finding a common basis for the different forms of\ndeception.\n4. Finding common linguistic cues and invariants across\nthe different forms of deception. Some evidence is\nreported in [33].\n5. Dealing with imbalanced data. Deceptive attacks, by\ntheir nature, would be targeted, e.g., spearphishing, or\noverly broad, such as spam or phishing. This gives rise\nto imbalanced scenarios. An adapter, Prexia, is reported\nin [2].\n6. Distributed nature. People and companies are uncom-\n\nfortable sharing sensitive information, such as targeted\nattacks (spearphishing). Can we design models that can\nwork with limited shared data?\n7. Human in the loop. Can the detector improve human\nability? Can humans improve the detector\u2019s ability with\njust a few examples? Or by providing access to his/her\ncognitive load through a sensor?\n5 Defining Success\nIdeally, we would achieve a deception detection model that\ndoes not need any labeled data to detect new attacks since it\nis based on invariants of deception. However, this may be\ntoo difficult a holy grail to achieve. Thus, success would be\na detector that helps the human in the loop do significantly\nbetter at resisting attacks (e.g., a novice email user can\ndetect quite sophisticated spearphishing attacks). If we can\nachieve this goal, then we can start researching the problem\nof building teachable detectors so that the human and the\ndetector can improve each other.\n6 Possible Solution\nIn this section, we present a preliminary solution to address\nthe problem outlined in this work. Our proposed approach\nleverages the power of advanced, large-scale, multilingual,\nand multimodal contextual learners, complemented by Re-\ntrieval Augmented Generation (RAG). It is important to note\nthat this approach is just one of several promising avenues\nthat warrant further exploration.\nTo lay the foundation for a potential solution, we ini-\ntially focus on a single modality, namely text. In this con-\nfiguration, we aim to create a system capable of identifying\ndeceptive text in a domain-agnostic and multilingual con-\ntext. To ensure the system\u2019s relevance and effectiveness,\nwe aim to imbue it with desirable attributes, including result\nexplainability and robust zero to few-shot performance. To\nachieve these characteristics, a logical system design might\ninvolve the integration of an exceptionally large-scale lan-\nguage model that excels in contextual learning, such as Mis-\ntral [17]. This model can achieve superior performance in\nthe task, regardless of the domain, and remains resilient in\nthe face of diverse data distributions. To further enhance its\nexplainability, the model can undergo instruction tuning, en-\nabling it to deliver answers and elucidate its underlying rea-\nsoning.\nTo elevate its already outstanding zero to few-shot capa-\nbilities and achieve performance parity with fully fine-tuned\nspecialized models in specific domains, it is advisable to\naugment the learner with a Retrieval Augmented Generation\n(RAG) infrastructure, as proposed by [19]. This design de-\ncision ensures the longevity of the system and its\u2019 ability to\nstay up-to-date with current threats because it makes contin-\nuous finetuning unnecessary.\nA standard RAG system\u2019s high-level system design\nscheme is shown in Figure 1. It consists of mining-derived\ndatasets indexed and stored in a vector database, accessed\nthrough FAISS [7] (Facebook AI Similarity Search) or any\nother approximate nearest neighbors algorithm optimized for\nsearching large vector spaces. Combined with Retrieval-\nAugmented Generation (RAG) techniques [19], this infras-\ntructure delivers critical context to enhance Mistral\u2019s perfor-\nmance. This system design is a decision-making tool that\ndetects deceptive text followed by a clear explanation of this\ndecision. Moreover, enhancing the LLM input prompt with\nretrieved context guarantees the model has all the necessary\ninformation to generate a comprehensive response.\nWhen presented with a single instance of a task, typi-\ncally a query from a user, the steps in solving the problem\n(each step is referenced in Figure 1 as (1),(2),(3), or (4)) are:\n1. Create Initial Prompt: Starting with the user query.\n2. Augment Prompt with Retrieved Context: Merges the\ninitial prompt with the context retrieved from the Vector\nStore, creating an enriched input for the LLM.\n3. Send Augmented Prompt to LLM:The LLM receives the\nenhanced prompt.\n4. Receive LLM\u2019s Response: After processing the aug-\nmented prompt, it generates its response.\nFigure 1: High-level overview of a possible solution using\nRAG and a multi-modal in-context learner. The dashed line\ndepicts the retrieval of context and its integration into the\nquery.\nA multimodal LLM is necessary to extend this approach\nto multiple modalities, e.g., a unified multimodal model, or\nUnIV AL [32], which unifies text, images, video, and audio\ninto a single model. Thus, it may be possible to use UnIV AL,\nor other multimodal models such as OPENAI\u2019s CLIP 4, in\n4https://www.pinecone.io/learn/series/\nimage-search/clip/\n\nplace of a single-mode model like Mistral [17]. In addition,\nother components, such as RAG, may need to be adjusted\nas needed. However, most problems to be solved are in the\nengineering space.\nFrom a research perspective, the main challenge in de-\nsigning and implementing a functional system as described\nis model performance as a function of model size and the\ncurrent lack of multimodal in-context learners that are large\nenough to perform satisfactorily. For text, we notice that\nmodels of 2-3B parameters score 0.25 or so on the Hugging-\nFace LLM benchmark, 7B score 0.73, and 170B score 0.75;\nin other words, there is a massive jump from 3B to 7B pa-\nrameters followed by a plateau. So, to have a truly intelli-\ngent model, it needs to be at least 7B for a single modality,\nas a rule of thumb - although it may be possible to bring\nthis number down through quantization and other means.\nMultiple modalities may require larger models for similar\nperformance. Currently, UnIV AL has only 0.25B parame-\nters. Therefore, we hypothesize that such a system as we\ndescribed would be made possible by an advance in models\nlike UnIV AL - multimodal transformers that learn in context\nand have billions of parameters. Perhaps, Flamingo with 80B\nparameters [1] can help here.\n7 Conclusions\nIn this paper, we introduce a new concept \u201cMultilingual,\nMultimodal Domain-independence Deception Detection\u201d\nthat unifies diverse investigations, creating a new paradigm\nfor detecting deceitful behavior across languages and modal-\nities. This innovative approach harmoniously connects pre-\nvious research in multimodal and cross-lingual deception de-\ntection, paving the way for future breakthroughs. We discuss\nthe research challenges related to this concept and also po-\ntential solutions.\nAcknowledgments.\nResearch partly supported by NSF grants 2210198\nand 2244279, and ARO grants W911NF-20-1-0254 and\nW911NF-23-1-0191. Verma is the founder of Everest Cy-\nber Security and Analytics, Inc.\nReferences\n[1] J.-B. A LAYRAC , J. D ONAHUE , P. L UC, A. M IECH ,\nI. B ARR , Y. H ASSON , K. L ENC , A. M ENSCH , K. M IL-\nLICAN , M. R EYNOLDS , R. R ING , E. R UTHERFORD ,\nS. C ABI , T. H AN, Z. G ONG , S. S AMANGOOEI , M. M ON-\nTEIRO , J. M ENICK , S. B ORGEAUD , A. B ROCK , A. N E-\nMATZADEH , S. S HARIFZADEH , M. B INKOWSKI , R. B AR-\nREIRA , O. V INYALS , A. Z ISSERMAN , AND K. S IMONYAN ,\nFlamingo: a visual language model for few-shot learning ,\n2022.\n[2] D. B OUMBER , F. Z. Q ACHFAR , AND R. M. V ERMA ,\nDomain-agnostic adapter architecture for deception detec-\ntion: Extensive evaluations with the difraud benchmark , in\nJoint International Conference on Computational Linguistics,\nLanguage Resources and Evaluation, Torino, Italy, May 2024,\nEuropean Language Resources Association.\n[3] P. C APUOZZO , I. L AURIOLA , C. S TRAPPARAVA ,\nF. A IOLLI , AND G. S ARTORI , Decop: A multilingual\nand multi-domain corpus for detecting deception in typed\ntext, in Proceedings of the Twelfth Language Resources and\nEvaluation Conference, 2020, pp. 1423\u20131430.\n[4] W. C ERON , M.-F. DE LIMA -SANTOS , AND M. G. Q UILES ,\nFake news agenda in the era of covid-19: Identifying trends\nthrough fact-checking content. online social networks and\nmedia, 21, 100116, 2020.\n[5] V. M. H. D ANG AND R. M. V ERMA , Data quality in\nNLP: Metrics and a comprehensive taxonomy , in Interna-\ntional Symposium on Intelligent Data Analysis, Springer,\n2024, pp. 217\u2013229.\n[6] J. D EVLIN , M.-W. C HANG , K. L EE, AND K. T OUTANOVA ,\nBert: Pre-training of deep bidirectional transformers for\nlanguage understanding, 2019.\n[7] M. D OUZE , A. G UZHVA , C. D ENG , J. J OHNSON ,\nG. S ZILVASY, P.-E. M AZAR \u00b4E, M. L OMELI , L. H OS-\nSEINI , AND H. J \u00b4EGOU , The faiss library , arXiv preprint\narXiv:2401.08281, (2024).\n[8] A. E L AASSAL , S. B AKI , A. D AS, AND R. M. V ERMA ,\nAn in-depth benchmarking and evaluation of phishing de-\ntection research for security needs , IEEE Access, 8 (2020),\npp. 22170\u201322192.\n[9] S. F ENG , R. B ANERJEE , AND Y. CHOI , Syntactic stylometry\nfor deception detection, in Annual Meeting of the Association\nfor Computational Linguistics, 2012.\n[10] M. G LENSKI , E. A YTON , R. C OSBEY , D. A RENDT , AND\nS. V OLKOVA, Towards trustworthy deception detection:\nBenchmarking model robustness across domains, modalities,\nand languages, in Proceedings of the 3rd International Work-\nshop on Rumours and Deception in Social Media (RDSM),\nBarcelona, Spain (Online), Dec. 2020, Association for Com-\nputational Linguistics, pp. 1\u201313.\n[11] T. G R \u00a8ONDAHL AND N. A SOKAN , Text analysis in adversar-\nial settings: Does deception leave a stylistic trace? , ACM\nComputing Surveys (CSUR), 52 (2019), pp. 1\u201336.\n[12] A. H AMID , N. S HIEKH , N. S AID , K. A HMAD , A. G UL,\nL. H ASSAN , AND A. A L-FUQAHA , Fake news detection in\nsocial media using graph neural networks and nlp techniques:\nA covid-19 use-case , arXiv preprint arXiv:2012.07517,\n(2020).\n[13] F. H AOUARI , M. H ASANAIN , R. S UWAILEH , AND T. E L-\nSAYED , Arcov19-rumors: Arabic covid-19 twitter dataset for\nmisinformation detection, arXiv preprint arXiv:2010.08768,\n(2020).\n[14] M. H ASANAIN , F. A LAM , H. M UBARAK , S. A BDALJALIL ,\nW. Z AGHOUANI , P. N AKOV, G. D A SAN MARTINO , AND\nA. F REIHAT , Araieval shared task: Persuasion techniques\nand disinformation detection in arabic text , in Proceedings\nof the First Arabic Natural Language Processing Conference\n(ArabicNLP 2023), Singapore, Dec. 2023, Association for\n\nComputational Linguistics.\n[15] \u00b4A. H ERN \u00b4ANDEZ -CASTA \u02dcNEDA , H. C ALVO, A. G ELBUKH ,\nAND J. J. G. F LORES , Cross-domain deception detection\nusing support vector networks , Soft Computing, 21 (2017),\npp. 585\u2013595.\n[16] N. H USSAIN , H. T. M IRZA , I. H USSAIN , F. I QBAL ,\nAND I. M EMON , Spam review detection using the linguistic\nand spammer behavioral methods , IEEE Access, 8 (2020),\npp. 53801\u201353816.\n[17] A. Q. J IANG , A. S ABLAYROLLES , A. M ENSCH , C. B AM-\nFORD , D. S. C HAPLOT , D. DE LAS CASAS , F. B RESSAND ,\nG. L ENGYEL , G. L AMPLE , L. S AULNIER , L. R. L AVAUD,\nM.-A. L ACHAUX , P. S TOCK , T. L. S CAO , T. L AVRIL ,\nT. W ANG , T. L ACROIX , AND W. E. S AYED, Mistral 7b ,\n2023.\n[18] T. R. L EVINE , Encyclopedia of Deception , vol. 2, Sage\nPublications, 2014.\n[19] P. L EWIS , E. P EREZ , A. P IKTUS , F. P ETRONI ,\nV. K ARPUKHIN , N. G OYAL, H. K \u00a8UTTLER , M. L EWIS ,\nW. TAU YIH, T. R OCKT \u00a8ASCHEL , S. R IEDEL , AND\nD. K IELA , Retrieval-augmented generation for knowledge-\nintensive nlp tasks, 2021.\n[20] H. L I, Z. C HEN , A. M UKHERJEE , B. L IU, AND J. S HAO,\nAnalyzing and detecting opinion spam on a large-scale\ndataset via temporal and spatial patterns , in Proceedings of\nthe international AAAI conference on web and social media,\nvol. 9, 2015, pp. 634\u2013637.\n[21] J. L I, L. YANG , AND P. ZHANG , Shooting review spam with\na weakly supervised approach and a sentiment-distribution-\noriented method, Applied Intelligence, 53 (2022), pp. 10789\u2013\n10799.\n[22] Y. L I, B. J IANG , K. S HU, AND H. L IU, Mm-covid: A\nmultilingual and multimodal data repository for combating\ncovid-19 disinformation , arXiv preprint arXiv:2011.04088,\n(2020).\n[23] P. M EHDI GHOLAMPOUR AND R. M. V ERMA , Adversarial\nrobustness of phishing email detection models, in Proceedings\nof the 9th ACM International Workshop on Security and\nPrivacy Analytics, 2023, pp. 67\u201376.\n[24] A. M UKHERJEE , V. V ENKATARAMAN , B. L IU, AND N. S.\nGLANCE , What yelp fake review filter might be doing? ,\nProceedings of the International AAAI Conference on Web\nand Social Media, (2013).\n[25] K. P APANTONIOU , P. P APADAKOS , G. F LOURIS , AND\nD. P LEXOUSAKIS , Linguistic cues of deception in a multi-\nlingual april fools\u2019 day context, in Proceedings of the Eighth\nItalian Conference on Computational Linguistics, CLiC-it\n2021, Milan, Italy, January 26-28, 2022, E. Fersini, M. Pas-\nsarotti, and V . Patti, eds., vol. 3033 of CEUR Workshop Pro-\nceedings, CEUR-WS.org, 2021.\n[26] N. R EIMERS AND I. G UREVYCH , Sentence-bert: Sentence\nembeddings using siamese bert-networks, 2019.\n[27] Y. R EN AND D. J I, Neural networks for deceptive opinion\nspam detection: An empirical study , Information Sciences,\n385-386 (2017), pp. 213\u2013224.\n[28] R. R ILL -GARC \u00b4IA, L. V ILLASE \u02dcNOR -PINEDA , V. R EYES -\nMEZA , AND H. J. E SCALANTE , From text to speech: A\nmultimodal cross-domain approach for deception detection ,\nin CV AUI/IWCF/MIPPSNA@ICPR, 2018.\n[29] J. S ALMINEN , C. K ANDPAL , A. M. K AMEL , S.- G. J UNG ,\nAND B. J. J ANSEN , Creating and detecting fake reviews of\nonline products, Journal of Retailing and Consumer Services,\n64 (2022), p. 102771.\n[30] J. S \u00b4ANCHEZ -JUNQUERA , L. V ILLASE \u02dcNOR -PINEDA , M. M.\nY G \u00b4OMEZ , P. R OSSO , AND E. S TAMATATOS, Masking\ndomain-specific information for cross-domain deception de-\ntection, Pattern Recognit. Lett., 135 (2020), pp. 122\u2013130.\n[31] S. S HAHRIAR , A. MUKHERJEE , AND O. GNAWALI, Improv-\ning phishing detection via psychological trait scoring, 2022.\n[32] M. S HUKOR , C. D ANCETTE , A. R AME , AND M. C ORD ,\nUnival: Unified model for image, video, audio and language\ntasks, Transactions on Machine Learning Research Journal,\n(2023).\n[33] R. M. V ERMA , N. D ERSHOWITZ , V. Z ENG , D. B OUM -\nBER , AND X. L IU, Domain-independent deception: A\nnew taxonomy and linguistic analysis , arXiv preprint\narXiv:2402.01019, (2024).\n[34] R. M. V ERMA , N. D ERSHOWITZ , V. Z ENG , AND X. L IU,\nDomain-independent deception: Definition, taxonomy and\nthe linguistic cues debate, 2022.\n[35] R. M. V ERMA , V. Z ENG , AND H. FARIDI , Data quality for\nsecurity challenges: Case studies of phishing, malware and\nintrusion detection datasets, in Proceedings of the 2019 ACM\nSIGSAC Conference on Computer and Communications Se-\ncurity, 2019, pp. 2605\u20132607.\n[36] S. V OLKOVA , E. A YTON , D. L. A RENDT , Z. H UANG , AND\nB. H UTCHINSON , Explaining multimodal deceptive news\nprediction models, in International Conference on Web and\nSocial Media, 2019.\n[37] V. Z ENG , X. LIU, AND R. M. V ERMA , Does deception leave\na content independent stylistic trace? , in Proceedings of the\nTwelfth ACM Conference on Data and Application Security\nand Privacy, CODASPY \u201922, New York, NY , USA, 2022,\nAssociation for Computing Machinery, p. 349\u2013351.\n[38] W. Z HANG , Y. D U, T. Y OSHIDA , AND Q. W ANG , Dri-\nrcnn: An approach to deceptive review identification using\nrecurrent convolutional neural network, Inf. Process. Manag.,\n54 (2018), pp. 576\u2013592.",
  "metadata": {
    "title": "",
    "author": "",
    "pages": 6,
    "source_file": "Verma_2024_Roadmap_for_Multilingual_Multimodal_Domain.pdf",
    "pdf_library": "pypdf"
  },
  "page_mapping": {
    "0": [
      1,
      0,
      5021
    ],
    "5021": [
      2,
      5021,
      10768
    ],
    "10768": [
      3,
      10768,
      13858
    ],
    "13858": [
      4,
      13858,
      18408
    ],
    "18408": [
      5,
      18408,
      23867
    ],
    "23867": [
      6,
      23867,
      28829
    ]
  }
}